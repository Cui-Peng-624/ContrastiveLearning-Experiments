{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d446008e-3f63-44b3-9c5e-acad065ef08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01c8e7-9347-4a1e-ba33-ad2578a937b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unzip import unzip_file\n",
    "\n",
    "# # 指定zip文件的路径\n",
    "# zip_file_path = './data/archive.zip'\n",
    "# extract_to_path = './data/'\n",
    "\n",
    "# unzip_file(zip_file_path, extract_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5cc957e-ba08-4e54-9bec-6a5b95b16b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "batch_size = 16\n",
    "num_negative_batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f00d1fa-75a5-4d9e-87b0-9bf800c087f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 100000\n",
      "验证集大小: 10000\n"
     ]
    }
   ],
   "source": [
    "# 1. 数据预处理和增强\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256),        # 随机裁剪 64x64 图像，因为Tiny-ImageNet图像是64x64\n",
    "    transforms.RandomHorizontalFlip(p=0.5),   # 50% 概率水平翻转\n",
    "    transforms.Grayscale(num_output_channels=3), # 转为灰度图\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 2. 加载 Tiny-ImageNet 数据集\n",
    "train_dir = './data/tiny-imagenet-200/train'\n",
    "val_dir = './data/tiny-imagenet-200/val'\n",
    "\n",
    "# 使用 ImageFolder 加载数据集\n",
    "trainset = ImageFolder(root=train_dir, transform=transform)\n",
    "valset = ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "# 3. 创建数据加载器\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 查看数据集的一些信息\n",
    "print(f\"训练集大小: {len(trainset)}\")\n",
    "print(f\"验证集大小: {len(valset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "024caa8d-6783-4baa-ac44-0722cea0f84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 256, 256]) torch.Size([16]) tensor([144,  56, 112, 172, 162,  37, 113, 143, 199, 169, 136,  57, 150, 142,\n",
      "        111, 159])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for a,b in trainloader:\n",
    "    print(a.shape, b.shape, b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b01940-81dc-4656-849f-2c57b7d0b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义编码器（ResNet-101）并提取第三残差块输出\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.resnet = resnet101(pretrained=False)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:6])  # 提取第三残差块输出\n",
    "\n",
    "        # 随机裁剪 60x60 并填充回 64x64\n",
    "        self.random_crop_and_pad = transforms.Compose([\n",
    "            transforms.RandomCrop(60),    # 随机裁剪出 60x60\n",
    "            transforms.Pad(2)             # 填充回 64x64（2像素的填充）\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 对每个 256x256 图像进行 7x7 的 64x64 的网格裁剪，每个裁剪之间有32像素的重叠\n",
    "        patches = x.unfold(2, 64, 32).unfold(3, 64, 32) # 1.在第三个维度上提取大小为64的局部块，步长为32。2.在第四个维度上提取大小为64的局部块，步长为32。\n",
    "        # print(\"###\", patches.shape, \"###\") # torch.Size([batch_size, channels, 7, 7, 64, 64])\n",
    "        patches = patches.contiguous().view(-1, 3, 64, 64)  # 展开为一批 64x64 小块\n",
    "        # print(\"###\", patches.shape, \"###\") # torch.Size([784, 3, 64, 64])\n",
    "\n",
    "        # 对每个 64x64 的小块执行随机 60x60 裁剪并填充回 64x64\n",
    "        patches = torch.stack([self.random_crop_and_pad(patch) for patch in patches]) # 每一个小patch.shape=torch.Size([3, 64, 64])\n",
    "        # print(\"###\", patches.shape, \"###\") # ### torch.Size([784, 3, 64, 64]) ###\n",
    "        # for patch in patches:\n",
    "        #     print(self.random_crop_and_pad(patch)) # torch.Size([3, 64, 64])\n",
    "        \n",
    "        features = self.resnet(patches)  # 提取特征\n",
    "        # print(\"###\", features.shape, \"###\") # ### torch.Size([784, 512, 8, 8]) ###\n",
    "        features = nn.functional.adaptive_avg_pool2d(features, (1, 1))  # 全局池化\n",
    "        # print(\"###\", features.shape, \"###\") # ### torch.Size([784, 512, 1, 1]) ###\n",
    "        # features = features.view(-1, 512)  # [B, 1024]，每个小块的 1024 维向量\n",
    "        # print(\"###\", features.shape, \"###\") # ### torch.Size([392, 1024]) ###\n",
    "        features = features.view(batch_size, 7, 7, -1)  # 恢复为 [B, 7, 7, 1024]\n",
    "        # print(\"###\", features.shape, \"###\") # ### torch.Size([8, 7, 7, 1024]) ###\n",
    "        # 要把1024调整512才可以适应batch_size\n",
    "\n",
    "        return features # shape=[batch_size=16, 7, 7, 512]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7223ee-976c-45ce-87e0-e9edd4857c13",
   "metadata": {},
   "source": [
    "在你提供的代码中，`features.shape=torch.Size([784, 512, 8, 8])`，表示提取出来的特征张量具有四个维度。我们可以分别解释这些维度：\r\n",
    "\r\n",
    "### 特征张量的维度解释\r\n",
    "\r\n",
    "1. **784 (第一个维度)**：\r\n",
    "   - 这是批次中包含的**图像块的数量**。你使用了 `x.unfold(2, 64, 32).unfold(3, 64, 32)` 将输入的图像裁剪成了多个 64x64 的小块（每张 256x256 图像被分成了 7x7 个 64x64 的局部块）。\r\n",
    "   - 假设你的批量大小是 1（即一次输入一张 256x256 的图像），那么每张图像会产生 7x7 = 49 个 64x64 的小块。如果有 16 张图像，那么总共有 16 × 49 = 784 个小块，所以这个维度是 **784**。\r\n",
    "   - 具体来说：`784 = 16 * 49`，其中 16 是批量大小，49 是每张图像裁剪的小块数量。\r\n",
    "\r\n",
    "2. **512 (第二个维度)**：\r\n",
    "   - 这是每个图像块提取出来的**特征通道数**，在你的代码中，这来自 `resnet101` 的第三个残差块输出。`resnet101` 的特征输出在第3个残差块后的通道数是 **512**。\r\n",
    "   - 这意味着对于每个 64x64 的图像块，`ResNet` 提取了 512 个特征通道，用于表示图像块的不同特征。\r\n",
    "\r\n",
    "3. **8 (第三个维度)**：\r\n",
    "   - 这是提取的特征图的**高度**。由于 `resnet101` 中的卷积和池化操作会逐渐降低特征图的空间维度，输入的 64x64 的图像块经过 ResNet 的前几个残差块后，特征图的空间维度从 64x64 减少到了 8x8。\r\n",
    "   - 这个数字表示每个图像块在特征空间中被分成了 8x8 的小块。\r\n",
    "\r\n",
    "4. **8 (第四个维度)**：\r\n",
    "   - 这是提取的特征图的**宽度**，同样是由 `resnet101` 的卷积和池化操作导致的。和高度维度类似，原始的 64x64 图像块经过卷积后，宽度也被缩减到了 8。\r\n",
    "\r\n",
    "### 总结：\r\n",
    "- **784**：总共有 784 个图像块，这是批量中所有图像被裁剪成的小块总数。\r\n",
    "- **512**：每个图像块的特征通道数，即从 `resnet101` 中提取的 512 个通道特征。\r\n",
    "- **8x8**：每个图像块在经过 `ResNet101` 后的特征图的空间大小。原始的 64x64 图像块被压缩到 8x8 的特征图。\r\n",
    "\r\n",
    "因此，`features.shape = torch.Size([784, 512, 8, 8])` 表示有 784 个 64x64 的图像块，它们分别被表示为具有 512 个通道和 8x8 空间分辨率的特征图。这些特征可以捕捉到每个块中更高层次的空间和语义信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69b353-2f10-4591-9a6d-44ae0d9ce0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# if __name__ == \"__main__\":\n",
    "#     model = Encoder()\n",
    "#     x = torch.randn(4, 3, 256, 256)  # 模拟 4 张 256x256 的 RGB 图像\n",
    "#     output = model(x)\n",
    "#     print(output.shape)  # 应输出 [4, 7, 7, 1024]，实际输出：torch.Size([2, 7, 7, 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a680bad9-a18c-497b-9697-600352fb2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. PixelCNN 风格的自回归模型（使用 GRU 作为示例）\n",
    "class AutoregressiveModel(nn.Module):\n",
    "    def __init__(self, input_dim=512, hidden_dim=512):\n",
    "        super(AutoregressiveModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):  # shape=[batch_size=16, 7, 7, 512]\n",
    "        B, H, W, D = x.size()  # [B, 7, 7, 512]\n",
    "        x = x[:, :2, :, :]  # 取前两行作为 GRU 的输入 [B, 2, 7, 512]\n",
    "        x = x.view(B, 2 * W, D)  # 展开为序列 [B, 14, 512]\n",
    "\n",
    "        output, hidden = self.gru(x)  # GRU 输出 [B, 14, hidden_dim]，hidden [1, B, hidden_dim]\n",
    "        last_hidden = hidden[-1]  # 取最后一个时间步的隐藏状态 [B, hidden_dim]\n",
    "        # print(last_hidden.shape) # torch.Size([16, 512])\n",
    "\n",
    "        # 复制 last_hidden 5*7 次，以适配后续的形状 [B, 5, 7, hidden_dim]\n",
    "        last_hidden = last_hidden.unsqueeze(1).unsqueeze(1)  # [B, 1, 1, hidden_dim]\n",
    "        last_hidden = last_hidden.expand(B, 5, 7, D)  # [B, 5, 7, 512]\n",
    "\n",
    "        return last_hidden  # 作为 query 返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58316b3-a3e3-4cc0-a5d5-9cb0162cea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test AutoregressiveModel\n",
    "ARModel = AutoregressiveModel()\n",
    "test = torch.randn(batch_size, 7, 7, 512)\n",
    "test = ARModel(test)\n",
    "# print(\"###\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3820b7a9-7187-4946-8710-02ccaae3a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CPC模型\n",
    "class CPCModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CPCModel, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.autoregressive = AutoregressiveModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)  # 提取每个64x64块的特征 [B, 7, 7, 512]\n",
    "        c = self.autoregressive(z)  # 预测后五行特征 [B, 5, 7, 512]\n",
    "        return z, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d946fe9e-944f-4b0d-a502-4c57302e9964",
   "metadata": {},
   "source": [
    "正样本：是未来时刻的输入（例如7*7的patches，我们选定一个时刻比如第五行最后一列，那么之后的两行都是未来时刻）经过编码器的输出z     \n",
    "负样本：任意输入，经过编码器的输出都应该和未来时刻的输出经过编码器的输出不相似"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44eff09-48cf-434b-9b4f-994714cdb622",
   "metadata": {},
   "source": [
    "问题的关键是：正样本对定义中，自回归模型的输出c和特征提取模型的输出z之间的对应关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca2537-f7f1-4c77-8410-9fa4717c10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 对比损失 (InfoNCE)\n",
    "# class InfoNCELoss(nn.Module):\n",
    "#     def __init__(self, temperature=0.07):\n",
    "#         super(InfoNCELoss, self).__init__()\n",
    "#         self.temperature = temperature\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, z_i, z_j): # criterion(c.reshape(-1, 512), z.reshape(-1, 512)) # z_i，z_j.shape=(16*7*7, 512)\n",
    "#         B = z_i.size(0) # 16*7*7\n",
    "#         z_i = nn.functional.normalize(z_i, dim=1) # dim=1代表每行归一化：除以\\sqrt{每个元素的平方之和} - 特征归一化\n",
    "#         z_j = nn.functional.normalize(z_j, dim=1)\n",
    "\n",
    "#         # 相似性矩阵\n",
    "#         similarity_matrix = torch.matmul(z_i, z_j.T) / self.temperature # torch.matmul(z_i, z_j.T) - 16*7*7 与 16*7*7 patches 之间的相似度\n",
    "\n",
    "#         # 标签：对角线位置是正样本\n",
    "#         labels = torch.arange(B).to(device)\n",
    "#         loss = self.criterion(similarity_matrix, labels) # similarity_matrix.shape=(16*7*7, 16*7*7), labels.shape=(16*7*7)\n",
    "\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff90257-0806-4bdb-9d1c-bcef5ae4c85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2249)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 初始化模型、损失函数和优化器\n",
    "from InfoNCE import InfoNCE\n",
    "\n",
    "model = CPCModel().to(device)\n",
    "criterion = InfoNCE()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "# test loss\n",
    "batch_size, num_negative, embedding_size = 32, 48, 128\n",
    "query = torch.randn(batch_size, embedding_size)\n",
    "positive_key = torch.randn(batch_size, embedding_size)\n",
    "negative_keys = torch.randn(num_negative, embedding_size)\n",
    "output = criterion(query, positive_key, negative_keys)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b99dd22-d1cf-4246-88a9-d4478eccb711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\envs\\DL_learning\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/6250: Loss: 6.6768\n",
      "Batch 1/6250: Loss: 6.4208\n",
      "Batch 2/6250: Loss: 6.1362\n",
      "Batch 3/6250: Loss: 5.8133\n",
      "Batch 4/6250: Loss: 5.6515\n",
      "Batch 5/6250: Loss: 5.1535\n",
      "Batch 6/6250: Loss: 4.9025\n",
      "Batch 7/6250: Loss: 4.6648\n",
      "Batch 8/6250: Loss: 4.4817\n",
      "Batch 9/6250: Loss: 3.9709\n",
      "Batch 10/6250: Loss: 3.6694\n",
      "Batch 11/6250: Loss: 3.7614\n",
      "Batch 12/6250: Loss: 2.9979\n",
      "Batch 13/6250: Loss: 2.9318\n",
      "Batch 14/6250: Loss: 3.2087\n",
      "Batch 15/6250: Loss: 3.1009\n",
      "Batch 16/6250: Loss: 2.7345\n",
      "Batch 17/6250: Loss: 2.8084\n",
      "Batch 18/6250: Loss: 2.0524\n",
      "Batch 19/6250: Loss: 2.2597\n",
      "Batch 20/6250: Loss: 2.1454\n",
      "Batch 21/6250: Loss: 1.6520\n",
      "Batch 22/6250: Loss: 2.2991\n",
      "Batch 23/6250: Loss: 2.0737\n",
      "Batch 24/6250: Loss: 2.1663\n",
      "Batch 25/6250: Loss: 2.1639\n",
      "Batch 26/6250: Loss: 1.6485\n",
      "Batch 27/6250: Loss: 1.1176\n",
      "Batch 28/6250: Loss: 1.1488\n",
      "Batch 29/6250: Loss: 1.0839\n",
      "Batch 30/6250: Loss: 1.3783\n",
      "Batch 31/6250: Loss: 1.4715\n",
      "Batch 32/6250: Loss: 0.9963\n",
      "Batch 33/6250: Loss: 1.4171\n",
      "Batch 34/6250: Loss: 1.1653\n",
      "Batch 35/6250: Loss: 1.1420\n",
      "Batch 36/6250: Loss: 0.9782\n",
      "Batch 37/6250: Loss: 1.0663\n",
      "Batch 38/6250: Loss: 0.7961\n",
      "Batch 39/6250: Loss: 0.7929\n",
      "Batch 40/6250: Loss: 0.9341\n",
      "Batch 41/6250: Loss: 0.7357\n",
      "Batch 42/6250: Loss: 0.5453\n",
      "Batch 43/6250: Loss: 0.3998\n",
      "Batch 44/6250: Loss: 0.7449\n",
      "Batch 45/6250: Loss: 0.6771\n",
      "Batch 46/6250: Loss: 0.4168\n",
      "Batch 47/6250: Loss: 0.5704\n",
      "Batch 48/6250: Loss: 0.7595\n",
      "Batch 49/6250: Loss: 0.7243\n",
      "Batch 50/6250: Loss: 0.4332\n",
      "Batch 51/6250: Loss: 0.7346\n",
      "Batch 52/6250: Loss: 0.5387\n",
      "Batch 53/6250: Loss: 0.5194\n",
      "Batch 54/6250: Loss: 0.3852\n",
      "Batch 55/6250: Loss: 0.6658\n",
      "Batch 56/6250: Loss: 0.4933\n",
      "Batch 57/6250: Loss: 0.3771\n",
      "Batch 58/6250: Loss: 0.4846\n",
      "Batch 59/6250: Loss: 0.3554\n",
      "Batch 60/6250: Loss: 0.4997\n",
      "Batch 61/6250: Loss: 0.5330\n",
      "Batch 62/6250: Loss: 0.4771\n",
      "Batch 63/6250: Loss: 0.3721\n",
      "Batch 64/6250: Loss: 0.6235\n",
      "Batch 65/6250: Loss: 0.3802\n",
      "Batch 66/6250: Loss: 0.4041\n",
      "Batch 67/6250: Loss: 0.4016\n",
      "Batch 68/6250: Loss: 0.3873\n",
      "Batch 69/6250: Loss: 0.3310\n",
      "Batch 70/6250: Loss: 0.2635\n",
      "Batch 71/6250: Loss: 0.3375\n",
      "Batch 72/6250: Loss: 0.3568\n",
      "Batch 73/6250: Loss: 0.2873\n",
      "Batch 74/6250: Loss: 0.2807\n",
      "Batch 75/6250: Loss: 0.2995\n",
      "Batch 76/6250: Loss: 0.3744\n",
      "Batch 77/6250: Loss: 0.3560\n",
      "Batch 78/6250: Loss: 0.2448\n",
      "Batch 79/6250: Loss: 0.2815\n",
      "Batch 80/6250: Loss: 0.2045\n",
      "Batch 81/6250: Loss: 0.2208\n",
      "Batch 82/6250: Loss: 0.2475\n",
      "Batch 83/6250: Loss: 0.2668\n",
      "Batch 84/6250: Loss: 0.2796\n",
      "Batch 85/6250: Loss: 0.2450\n",
      "Batch 86/6250: Loss: 0.2428\n",
      "Batch 87/6250: Loss: 0.3672\n",
      "Batch 88/6250: Loss: 0.2050\n",
      "Batch 89/6250: Loss: 0.2168\n",
      "Batch 90/6250: Loss: 0.2476\n",
      "Batch 91/6250: Loss: 0.3087\n",
      "Batch 92/6250: Loss: 0.2237\n",
      "Batch 93/6250: Loss: 0.2784\n",
      "Batch 94/6250: Loss: 0.2284\n",
      "Batch 95/6250: Loss: 0.2149\n",
      "Batch 96/6250: Loss: 0.1856\n",
      "Batch 97/6250: Loss: 0.1930\n",
      "Batch 98/6250: Loss: 0.1959\n",
      "Batch 99/6250: Loss: 0.1934\n",
      "Batch 100/6250: Loss: 0.2462\n",
      "Batch 101/6250: Loss: 0.1808\n",
      "Batch 102/6250: Loss: 0.1601\n",
      "Batch 103/6250: Loss: 0.1908\n",
      "Batch 104/6250: Loss: 0.1650\n",
      "Batch 105/6250: Loss: 0.2154\n",
      "Batch 106/6250: Loss: 0.1790\n",
      "Batch 107/6250: Loss: 0.1960\n",
      "Batch 108/6250: Loss: 0.1478\n",
      "Batch 109/6250: Loss: 0.2075\n",
      "Batch 110/6250: Loss: 0.1356\n",
      "Batch 111/6250: Loss: 0.1331\n",
      "Batch 112/6250: Loss: 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. 训练循环\n",
    "for epoch in range(10):  # 训练10个epoch\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(trainloader, 0):\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        z, c = model(inputs)\n",
    "        # z.shape = [16, 7, 7, 512]  # ResNet 提取的特征\n",
    "        # c.shape = [16, 5, 7, 512]  # 自回归模型生成的 query\n",
    "\n",
    "        # 取 ResNet 提取的后五行特征作为 positive_key\n",
    "        positive_key = z[:, 2:, :, :].reshape(-1, 512)  # [16*5*7, 512]\n",
    "\n",
    "        # 将 query 复制并展平 [16*5*7, 512]\n",
    "        query = c.reshape(-1, 512)\n",
    "\n",
    "        # 生成随机负样本，并通过 ResNet 编码为负样本特征\n",
    "        negative_samples = torch.randn(num_negative_batch, 3, 256, 256).to(device)  # 随机采样的负样本\n",
    "        negative_key = model.encoder(negative_samples)  # 使用 ResNet 编码为特征\n",
    "        negative_key = negative_key.reshape(-1, 512)  # 展平为 [N_negative, 512]\n",
    "\n",
    "        # 调用 InfoNCE 损失函数\n",
    "        loss = criterion(query, positive_key, negative_key)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 每 100 个 batch 打印一次损失\n",
    "        if batch_idx % 1 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(trainloader)}: Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7547045-9691-4d41-81b4-b05e25448fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a273d-23c9-4f11-bedd-63c4a19ace93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8ea32-9abb-48c8-bf26-410546b08fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
