{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01cdceee-a8b3-4af7-8dbd-2a65bb332205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "__all__ = ['InfoNCE', 'info_nce']\n",
    "\n",
    "\n",
    "class InfoNCE(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates the InfoNCE loss for self-supervised learning.\n",
    "    This contrastive loss enforces the embeddings of similar (positive) samples to be close\n",
    "        and those of different (negative) samples to be distant.\n",
    "    A query embedding is compared with one positive key and with one or more negative keys.\n",
    "\n",
    "    References:\n",
    "        https://arxiv.org/abs/1807.03748v2\n",
    "        https://arxiv.org/abs/2010.05113\n",
    "\n",
    "    Args:\n",
    "        temperature: Logits are divided by temperature before calculating the cross entropy.\n",
    "        reduction: Reduction method applied to the output.\n",
    "            Value must be one of ['none', 'sum', 'mean'].\n",
    "            See torch.nn.functional.cross_entropy for more details about each option.\n",
    "        negative_mode: Determines how the (optional) negative_keys are handled.\n",
    "            Value must be one of ['paired', 'unpaired'].\n",
    "            If 'paired', then each query sample is paired with a number of negative keys.\n",
    "            Comparable to a triplet loss, but with multiple negatives per sample.\n",
    "            If 'unpaired', then the set of negative keys are all unrelated to any positive key.\n",
    "\n",
    "    Input shape:\n",
    "        query: (N, D) Tensor with query samples (e.g. embeddings of the input).\n",
    "        positive_key: (N, D) Tensor with positive samples (e.g. embeddings of augmented input).\n",
    "        negative_keys (optional): Tensor with negative samples (e.g. embeddings of other inputs)\n",
    "            If negative_mode = 'paired', then negative_keys is a (N, M, D) Tensor.\n",
    "            If negative_mode = 'unpaired', then negative_keys is a (M, D) Tensor.\n",
    "            If None, then the negative keys for a sample are the positive keys for the other samples.\n",
    "\n",
    "    Returns:\n",
    "         Value of the InfoNCE Loss.\n",
    "\n",
    "     Examples:\n",
    "        >>> loss = InfoNCE()\n",
    "        >>> batch_size, num_negative, embedding_size = 32, 48, 128\n",
    "        >>> query = torch.randn(batch_size, embedding_size)\n",
    "        >>> positive_key = torch.randn(batch_size, embedding_size)\n",
    "        >>> negative_keys = torch.randn(num_negative, embedding_size)\n",
    "        >>> output = loss(query, positive_key, negative_keys)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, temperature=0.1, reduction='mean', negative_mode='unpaired'):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.reduction = reduction\n",
    "        self.negative_mode = negative_mode\n",
    "\n",
    "    def forward(self, query, positive_key, negative_keys=None):\n",
    "        return info_nce(query, positive_key, negative_keys,\n",
    "                        temperature=self.temperature,\n",
    "                        reduction=self.reduction,\n",
    "                        negative_mode=self.negative_mode)\n",
    "\n",
    "\n",
    "def info_nce(query, positive_key, negative_keys=None, temperature=0.1, reduction='mean', negative_mode='unpaired'):\n",
    "    # Check input dimensionality.\n",
    "    if query.dim() != 2:\n",
    "        raise ValueError('<query> must have 2 dimensions.')\n",
    "    if positive_key.dim() != 2:\n",
    "        raise ValueError('<positive_key> must have 2 dimensions.')\n",
    "    if negative_keys is not None:\n",
    "        if negative_mode == 'unpaired' and negative_keys.dim() != 2:\n",
    "            raise ValueError(\"<negative_keys> must have 2 dimensions if <negative_mode> == 'unpaired'.\")\n",
    "        if negative_mode == 'paired' and negative_keys.dim() != 3:\n",
    "            raise ValueError(\"<negative_keys> must have 3 dimensions if <negative_mode> == 'paired'.\")\n",
    "\n",
    "    # Check matching number of samples.\n",
    "    if len(query) != len(positive_key):\n",
    "        raise ValueError('<query> and <positive_key> must must have the same number of samples.')\n",
    "    if negative_keys is not None:\n",
    "        if negative_mode == 'paired' and len(query) != len(negative_keys):\n",
    "            raise ValueError(\"If negative_mode == 'paired', then <negative_keys> must have the same number of samples as <query>.\")\n",
    "\n",
    "    # Embedding vectors should have same number of components.\n",
    "    if query.shape[-1] != positive_key.shape[-1]:\n",
    "        raise ValueError('Vectors of <query> and <positive_key> should have the same number of components.')\n",
    "    if negative_keys is not None:\n",
    "        if query.shape[-1] != negative_keys.shape[-1]:\n",
    "            raise ValueError('Vectors of <query> and <negative_keys> should have the same number of components.')\n",
    "\n",
    "    # Normalize to unit vectors\n",
    "    query, positive_key, negative_keys = normalize(query, positive_key, negative_keys)\n",
    "    if negative_keys is not None:\n",
    "        # Explicit negative keys\n",
    "\n",
    "        # Cosine between positive pairs\n",
    "        positive_logit = torch.sum(query * positive_key, dim=1, keepdim=True) # 见“重要test - 逐元素相乘&转置相乘.ipynb”，shape=(batch_size, 1)\n",
    "\n",
    "        if negative_mode == 'unpaired':\n",
    "            # Cosine between all query-negative combinations\n",
    "            negative_logits = query @ transpose(negative_keys) # 就是每个query和negative_keys之间的相似度，shape=(batch_size, num_negative)\n",
    "\n",
    "        elif negative_mode == 'paired':\n",
    "            query = query.unsqueeze(1)\n",
    "            negative_logits = query @ transpose(negative_keys)\n",
    "            negative_logits = negative_logits.squeeze(1)\n",
    "\n",
    "        # First index in last dimension are the positive samples\n",
    "        logits = torch.cat([positive_logit, negative_logits], dim=1) # dim=1 加列，不使用广播机制\n",
    "        # print(positive_logit.shape, negative_logits.shape, logits.shape) # torch.Size([32, 1]) torch.Size([32, 48]) torch.Size([32, 49])\n",
    "        # print(len(logits)) # 32 - batch_size\n",
    "        labels = torch.zeros(len(logits), dtype=torch.long, device=query.device)\n",
    "    else:\n",
    "        # Negative keys are implicitly off-diagonal positive keys.\n",
    "\n",
    "        # Cosine between all combinations\n",
    "        logits = query @ transpose(positive_key)\n",
    "\n",
    "        # Positive keys are the entries on the diagonal\n",
    "        labels = torch.arange(len(query), device=query.device)\n",
    "\n",
    "    return F.cross_entropy(logits / temperature, labels, reduction=reduction)\n",
    "\n",
    "\n",
    "def transpose(x):\n",
    "    return x.transpose(-2, -1)\n",
    "\n",
    "\n",
    "def normalize(*xs):\n",
    "    return [None if x is None else F.normalize(x, dim=-1) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "762115c6-cb50-477b-853a-6084b7bcfe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0231)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "loss = InfoNCE()\n",
    "batch_size, num_negative, embedding_size = 32, 48, 128\n",
    "query = torch.randn(batch_size, embedding_size)\n",
    "positive_key = torch.randn(batch_size, embedding_size)\n",
    "negative_keys = torch.randn(num_negative, embedding_size)\n",
    "output = loss(query, positive_key, negative_keys)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd916c-b901-4311-a8b7-af9e0e664d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b931b7-d5c8-43de-a826-8d5f4935489f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
