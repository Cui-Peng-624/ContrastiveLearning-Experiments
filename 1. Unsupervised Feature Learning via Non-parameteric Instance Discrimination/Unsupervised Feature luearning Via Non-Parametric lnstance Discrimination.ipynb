{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e293e990-3826-4b14-b4cd-f79753895ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89919569-1b68-4b23-b086-de7405449c56",
   "metadata": {},
   "source": [
    "这段代码定义了一个数据预处理流水线，使用了 `torchvision.transforms` 模块中的多个变换操作。以下是对每个变换操作的解释：\r\n",
    "\r\n",
    "```python\r\n",
    "transform = transforms.Compose([\r\n",
    "    transforms.RandomResizedCrop(size=32),\r\n",
    "    transforms.RandomHorizontalFlip(),\r\n",
    "    transforms.ColorJitter(),\r\n",
    "    transforms.RandomGrayscale(p=0.2),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\r\n",
    "])\r\n",
    "```\r\n",
    "\r\n",
    "1. **`transforms.RandomResizedCrop(size=32)`**:\r\n",
    "   - 随机裁剪图像，并将其调整为指定大小（32x32）。\r\n",
    "   - 这个操作有助于模型学习不同尺度和位置的特征。\r\n",
    "\r\n",
    "2. **`transforms.RandomHorizontalFlip()`**:\r\n",
    "   - 以0.5的概率随机水平翻转图像。\r\n",
    "   - 这个操作有助于模型学习图像的对称性。\r\n",
    "\r\n",
    "3. **`transforms.ColorJitter()`**:\r\n",
    "   - 随机改变图像的亮度、对比度、饱和度和色调。\r\n",
    "   - 这个操作有助于模型学习对颜色变化的鲁棒性。\r\n",
    "\r\n",
    "4. **`transforms.RandomGrayscale(p=0.2)`**:\r\n",
    "   - 以0.2的概率将图像转换为灰度图像。\r\n",
    "   - 这个操作有助于模型学习对颜色信息的鲁棒性。\r\n",
    "\r\n",
    "5. **`transforms.ToTensor()`**:\r\n",
    "   - 将PIL图像或numpy数组转换为torch张量，并将像素值从[0, 255]范围缩放到[0, 1]范围。\r\n",
    "   - 这个操作是必需的，因为PyTorch模型期望输入是张量格式。\r\n",
    "\r\n",
    "6. **`transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))`**:\r\n",
    "   - 对图像张量进行标准化处理，使其均值为0，标准差为1。\r\n",
    "   - 这里的参数是针对CIFAR-10数据集的典型均值和标准差。\r\n",
    "   - 标准化操作有助于模型更快地收敛。\r\n",
    "\r\n",
    "这个预处理流水线可以应用于数据加载器中，以便在训练过程中对图像数据进行预处理。例如：\r\n",
    "\r\n",
    "```python\r\n",
    "from torchvision import datasets, transforms\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "# 定义数据预处理流水线\r\n",
    "transform = transforms.Compose([\r\n",
    "    transforms.RandomResizedCrop(size=32),\r\n",
    "    transforms.RandomHorizontalFlip(),\r\n",
    "    transforms.ColorJitter(),\r\n",
    "    transforms.RandomGrayscale(p=0.2),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\r\n",
    "])\r\n",
    "\r\n",
    "# 加载数据集并应用预处理\r\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\r\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\r\n",
    "```\r\n",
    "\r\n",
    "这样，`train_loader` 将会在每次迭代时自动应用定义的预处理流水线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc158f57-fe6e-4943-a823-f2f9db113f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 设置超参数\n",
    "batch_size = 128\n",
    "memory_bank_size = 50000  # CIFAR-10 有 50000 张训练图像\n",
    "feature_dim = 128  # 特征向量的维度\n",
    "negative_samples = 1024  # 每个 batch 选择的负样本数量\n",
    "\n",
    "## gpt - 数据增强方法 ###\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "### github 会报OverflowError错 ###\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(size=32, scale=(0.2,1.)),\n",
    "#     transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "#     transforms.RandomGrayscale(p=0.2),\n",
    "#     # transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# CIFAR-10 数据集\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e20124e-6d8f-4b92-9e85-fe4ef34bc5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for temp in train_loader:\n",
    "    a,b = temp\n",
    "    print(a.shape, b.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9f2a2-d648-4011-984e-df7a268d133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义编码器网络\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = torchvision.models.resnet18(pretrained=False, num_classes=feature_dim)\n",
    "        self.encoder.fc = nn.Sequential(nn.Linear(self.encoder.fc.in_features, feature_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054ab73-978d-430e-9f01-286bb25acca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder = Encoder()\n",
    "# print(Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da20b8-f09a-4e2d-8847-aad7e41dd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 Memory Bank\n",
    "class MemoryBank:\n",
    "    def __init__(self, size, dim):\n",
    "        self.size = size\n",
    "        self.dim = dim\n",
    "        self.memory = torch.randn(size, dim).cuda()\n",
    "        self.memory = nn.functional.normalize(self.memory, dim=1)\n",
    "\n",
    "    def update(self, indices, features):\n",
    "        # 更新 Memory Bank 中指定索引的特征\n",
    "        self.memory[indices] = nn.functional.normalize(features, dim=1)\n",
    "\n",
    "    def get_negatives(self, batch_size):\n",
    "        # 随机选择负样本\n",
    "        return torch.randint(0, self.size, (batch_size, negative_samples)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be55586-b51e-4995-881d-eeef329bbd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例辨别损失 (NCE)\n",
    "class NCELoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(NCELoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, features, positives, negatives):\n",
    "        batch_size = features.shape[0]\n",
    "        features = nn.functional.normalize(features, dim=1)\n",
    "        \n",
    "        # 计算正样本相似度\n",
    "        positive_logits = torch.sum(features * positives, dim=1).unsqueeze(1)\n",
    "        \n",
    "        # 计算负样本相似度\n",
    "        negative_logits = torch.matmul(features, negatives.T)\n",
    "        \n",
    "        # 拼接正负样本的相似度\n",
    "        logits = torch.cat([positive_logits, negative_logits], dim=1)\n",
    "        logits /= self.temperature\n",
    "        \n",
    "        # 创建标签，0 表示正样本\n",
    "        labels = torch.zeros(batch_size, dtype=torch.long).cuda()\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28a60f-1f6b-435e-a921-a4639cfcb154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d899290-3407-41f2-a346-7e4859e22438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型、损失函数和优化器\n",
    "model = Encoder(feature_dim=feature_dim).cuda()\n",
    "memory_bank = MemoryBank(size=memory_bank_size, dim=feature_dim)\n",
    "criterion = NCELoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d6408-3468-47e3-a2cf-47f6ebdbe1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程\n",
    "def train(model, train_loader, memory_bank, criterion, optimizer, epochs=200):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, (images, indices) in enumerate(train_loader):\n",
    "            images = images.cuda()\n",
    "            indices = indices.cuda()\n",
    "\n",
    "            # 提取特征\n",
    "            features = model(images)\n",
    "            \n",
    "            # 从 memory bank 中获取正样本和负样本\n",
    "            positives = memory_bank.memory[indices]\n",
    "            negatives_indices = memory_bank.get_negatives(batch_size)\n",
    "            negatives = memory_bank.memory[negatives_indices]\n",
    "\n",
    "            # 计算损失\n",
    "            loss = criterion(features, positives, negatives)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 更新 memory bank 中对应的特征\n",
    "            memory_bank.update(indices, features.detach())\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b480d98-74ce-49ff-9d31-969b9a3e4bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "train(model, train_loader, memory_bank, criterion, optimizer, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b27bc-2ab5-4eac-a0c4-9bc15bdc9ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d67db-2a81-463b-b3ba-ce4b2b04a575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046e139-5b23-4092-b03f-f56dc5d875ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
