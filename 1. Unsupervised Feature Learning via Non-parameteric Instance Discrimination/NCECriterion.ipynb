{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55cd4050-7452-4110-ae39-e02b04b4d31f",
   "metadata": {},
   "source": [
    "在代码注释中，`P(origin=model)`、`P(origin=noise)` 和 `P(noise=sample)` 分别表示以下含义：\r\n",
    "\r\n",
    "### 1. **`P(origin=model)`**\r\n",
    "- **含义**：表示输入特征 `x` 实际来自正样本的概率，即模型认为该样本来自原始数据分布的概率。\r\n",
    "- **解释**：在对比学习中，我们希望区分正样本（即原始数据的真实样本）和噪声样本（或负样本，通常为随机采样的其他样本）。`P(origin=model)` 是模型预测输入 `x` 是正样本的概率。这个概率通过计算正样本的相似度与所有样本相似度的比值来表示。\r\n",
    "\r\n",
    "### 2. **`P(origin=noise)`**\r\n",
    "- **含义**：表示输入特征 `x` 实际来自噪声样本的概率，即模型认为该样本来自噪声分布的概率。\r\n",
    "- **解释**：噪声样本是从所有可能的样本中随机选择的，并非原始数据分布中的样本。`P(origin=noise)` 是模型预测输入 `x` 是噪声样本的概率。这个概率是通过计算负样本的相似度与所有样本相似度的比值来表示的。\r\n",
    "\r\n",
    "### 3. **`P(noise=sample)`**\r\n",
    "- **含义**：表示一个样本被选作噪声样本的概率。\r\n",
    "- **解释**：`P(noise=sample)` 是先验概率，表示某个样本被当作噪声样本的概率。对于每一个样本，这个概率在训练集中是均匀分布的，因此为 `1 / nLem`，其中 `nLem` 是训练集中的样本总数。\r\n",
    "\r\n",
    "### 代码中这些概率的作用\r\n",
    "\r\n",
    "1. **`P(origin=model)`**:\r\n",
    "   - 该概率用于判断当前输入特征 `x` 是来自于正样本的可能性，是模型的输出（第 0 列）的概率。\r\n",
    "   - 在实现中，通过公式 `P(origin=model) = Pmt / (Pmt + K * Pnt)` 计算，其中 `Pmt` 是模型输出的相似度分数，`K * Pnt` 是噪声样本的贡献。\r\n",
    "\r\n",
    "2. **`P(origin=noise)`**:\r\n",
    "   - 该概率用于判断当前输入特征 `x` 是来自于噪声样本的可能性。\r\n",
    "   - 在实现中，通过公式 `P(origin=noise) = K * Pns / (Pms + K * Pns)` 计算，其中 `Pms` 是噪声样本的相似度分数，`K * Pns` 是噪声样本的先验概率。\r\n",
    "\r\n",
    "3. **`P(noise=sample)`**:\r\n",
    "   - 这是一个固定的先验概率，表示任何一个样本被作为噪声样本的概率。因为所有样本均匀分布，这个概率为 `1 / nLem`，其中 `nLem` 是所有样本的数量。\r\n",
    "\r\n",
    "### 总结\r\n",
    "\r\n",
    "- **`P(origin=model)`** 是模型预测输入特征 `x` 为正样本的概率。\r\n",
    "- **`P(origin=noise)`** 是模型预测输入特征 `x` 为噪声样本的概率。\r\n",
    "- **`P(noise=sample)`** 是一个样本被作为噪声样本的先验概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f3510-cd49-467b-8bec-a61afdd791a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "eps = 1e-7\n",
    "\n",
    "class NCECriterion(nn.Module):\n",
    "\n",
    "    def __init__(self, nLem):\n",
    "        super(NCECriterion, self).__init__()\n",
    "        self.nLem = nLem # nLem 表示 memory bank 的大小，即样本的总数\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        # x shape: [batchSize, K+1]\n",
    "        # targets shape: [batchSize]\n",
    "        # K is the number of noise samples\n",
    "        batchSize = x.size(0)\n",
    "        K = x.size(1)-1 # K 是负样本的数量，x 的第二维是 K+1（包括一个正样本和 K 个负样本）\n",
    "        Pnt = 1 / float(self.nLem)  # P(origin=noise)\n",
    "        Pns = 1 / float(self.nLem)  # P(noise=sample)\n",
    "        \n",
    "        # eq 5.1 : P(origin=model) = Pmt / (Pmt + k*Pnt) \n",
    "        Pmt = x.select(1,0)  # 1st column is the model output\n",
    "        Pmt_div = Pmt.add(K * Pnt + eps)\n",
    "        lnPmt = torch.div(Pmt, Pmt_div)\n",
    "        \n",
    "        # eq 5.2 : P(origin=noise) = k*Pns / (Pms + k*Pns)\n",
    "        Pon_div = x.narrow(1,1,K).add(K * Pns + eps)  # 2nd to last column are noise samples\n",
    "        Pon = Pon_div.clone().fill_(K * Pns)\n",
    "        lnPon = torch.div(Pon, Pon_div)\n",
    "     \n",
    "        # equation 6 in ref. A\n",
    "        lnPmt.log_()\n",
    "        lnPon.log_()\n",
    "        \n",
    "        lnPmtsum = lnPmt.sum(0)\n",
    "        lnPonsum = lnPon.view(-1, 1).sum(0)\n",
    "        \n",
    "        loss = - (lnPmtsum + lnPonsum) / batchSize\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13166e2c-fe78-41de-9c7b-c00058f452de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a18271-9621-427d-8299-31748e07a721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078257f-f0c3-4252-a1b3-d9669e229805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c3863e-2342-4662-82d7-65a5941f5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f78b3ea-2496-4de2-9be5-87caca4030bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Instance(datasets.CIFAR10):\n",
    "    \"\"\"CIFAR10Instance Dataset.\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416448d5-955b-4c44-971e-bb6145525eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=32, scale=(0.2,1.)),\n",
    "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = CIFAR10Instance(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10Instance(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838f9036-d7fb-4398-80ec-b0f842a119e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afecafe-0f05-4dfd-bfd1-aef88a0c3182",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (inputs, targets, indexes) in enumerate(trainloader):\n",
    "    inputs, targets, indexes = inputs.to(device), targets.to(device), indexes.to(device)\n",
    "    print(batch_idx, img.shape, target.shape, index.shape)\n",
    "    print(img, target, index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e4ec9-4554-4343-9e77-23f653383acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp in trainloader:\n",
    "    print(len(temp))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0091be-c280-4d72-b4c2-7bffb7dbce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,target,index in trainloader:\n",
    "    print(img.shape, target.shape, index.shape)\n",
    "    print(img, target, index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c90dc-8705-4bac-bc6a-fbd572401f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
