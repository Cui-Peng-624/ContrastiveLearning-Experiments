{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a5bdad-2d6a-451a-911d-c5f1cab32274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import math\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88535ed7-d74d-43bc-8134-7877088a8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Instance(torchvision.datasets.CIFAR10):\n",
    "    \"\"\"CIFAR10Instance Dataset.\"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            img, target = self.data[index], self.targets[index]\n",
    "        else:\n",
    "            img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        img = Image.fromarray(img) # 使用 Image.fromarray(img) 将从数据集中获取的 NumPy 数组（代表图像数据）转换为 PIL.Image.Image 对象，以便后续的图像处理操作\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None: # 如果 self.target_transform 不为 None，则对标签应用相应的转换。这可以用于标签的转换，例如将标签从一个格式转换到另一个格式\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432fab8-e625-4238-bb97-e6997ea87309",
   "metadata": {},
   "source": [
    "`target_transform` 通常用于对标签进行转换操作。例如，你可以使用它将分类标签从一个格式转换为另一个格式，或者对标签应用一些预处理操作。\n",
    "\n",
    "以下是一个简单的示例，展示如何使用 `target_transform` 来将标签从整数形式转换为独热编码（one-hot encoding）形式：\n",
    "\n",
    "### 示例：将标签转换为独热编码\n",
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 定义一个将标签转换为独热编码的转换函数\n",
    "def one_hot_encoding(target, num_classes=10):\n",
    "    one_hot = np.zeros(num_classes, dtype=np.float32)\n",
    "    one_hot[target] = 1.0\n",
    "    return one_hot\n",
    "\n",
    "# 扩展 CIFAR10 数据集并使用 target_transform 进行标签转换\n",
    "class CIFAR10Instance(torchvision.datasets.CIFAR10):\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # 将 NumPy 数组转换为 PIL 图像\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        # 应用图像转换\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 应用标签转换\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index\n",
    "\n",
    "# 使用 target_transform 来将标签转换为独热编码\n",
    "dataset = CIFAR10Instance(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    target_transform=lambda target: one_hot_encoding(target, num_classes=10)\n",
    ")\n",
    "\n",
    "# 从数据集中获取一个样本\n",
    "img, target, index = dataset[0]\n",
    "\n",
    "print(f\"Image Index: {index}\")\n",
    "print(f\"Original Label (One-Hot Encoded): {target}\")\n",
    "```\n",
    "\n",
    "### 解释：\n",
    "1. **`one_hot_encoding` 函数**：该函数接收一个整数标签，将其转换为具有 `num_classes` 个元素的独热编码（one-hot encoding）数组。例如，如果标签为 `3`，那么输出将是 `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`。\n",
    "2. **`target_transform` 参数**：当定义数据集时，使用 `target_transform=lambda target: one_hot_encoding(target, num_classes=10)` 将标签转换为独热编码。`lambda` 函数只是为了在定义数据集时传递参数到 `one_hot_encoding` 函数。\n",
    "3. **`__getitem__` 方法**：在重写的 `__getitem__` 方法中，如果 `target_transform` 不为 `None`，则对标签应用 `target_transform` 转换。\n",
    "\n",
    "### 输出：\n",
    "- 输出的 `target` 是独热编码形式的标签，而不是单一的整数标签。\n",
    "  \n",
    "**注意**：独热编码在深度学习中并不总是必要的，因为大多数 PyTorch 损失函数（如 `CrossEntropyLoss`）能够直接处理整数形式的分类标签。不过，如果你需要在特定任务中手动处理标签，这种方式非常有用。\n",
    "\n",
    "### 其他示例：\n",
    "你可以使用 `target_transform` 执行其他类型的标签转换，例如将标签转换为浮点数、归一化标签值，或为多标签分类任务生成多个标签。\n",
    "\n",
    "---\n",
    "\n",
    "**a.** 是否需要进一步扩展 `target_transform` 进行更复杂的标签转换？  \n",
    "**b.** 是否需要示例来处理回归任务中的标签转换？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4909165f-4ec9-496b-b4e2-24612eb272fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class AliasMethod(object):\n",
    "    '''\n",
    "        From: https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n",
    "    '''\n",
    "    def __init__(self, probs):\n",
    "\n",
    "        if probs.sum() > 1:\n",
    "            probs.div_(probs.sum())\n",
    "            \n",
    "        K = len(probs)\n",
    "        self.prob = torch.zeros(K)\n",
    "        self.alias = torch.LongTensor([0]*K)\n",
    "\n",
    "        # Sort the data into the outcomes with probabilities\n",
    "        # that are larger and smaller than 1/K.\n",
    "        smaller = []\n",
    "        larger = []\n",
    "        for kk, prob in enumerate(probs):\n",
    "            self.prob[kk] = K*prob\n",
    "            if self.prob[kk] < 1.0:\n",
    "                smaller.append(kk)\n",
    "            else:\n",
    "                larger.append(kk)\n",
    "\n",
    "        # larger和smaller储存的是索引\n",
    "        # Loop though and create little binary mixtures that\n",
    "        # appropriately allocate the larger outcomes over the\n",
    "        # overall uniform mixture.\n",
    "        while len(smaller) > 0 and len(larger) > 0:\n",
    "            small = smaller.pop()\n",
    "            large = larger.pop()\n",
    "\n",
    "            self.alias[small] = large\n",
    "            self.prob[large] = (self.prob[large] - 1.0) + self.prob[small]\n",
    "\n",
    "            if self.prob[large] < 1.0:\n",
    "                smaller.append(large)\n",
    "            else:\n",
    "                larger.append(large)\n",
    "\n",
    "        for last_one in smaller+larger:\n",
    "            self.prob[last_one] = 1\n",
    "\n",
    "    def cuda(self): \n",
    "        self.prob = self.prob.cuda()\n",
    "        self.alias = self.alias.cuda()\n",
    "\n",
    "    def draw(self, N):\n",
    "        '''\n",
    "            Draw N samples from multinomial\n",
    "        '''\n",
    "        K = self.alias.size(0)\n",
    "\n",
    "        kk = torch.zeros(N, dtype=torch.long, device=self.prob.device).random_(0, K) # 生成全为0,长度为N的张量,再随机从0-(K-1)中抽取数填充\n",
    "        prob = self.prob.index_select(0, kk)\n",
    "        alias = self.alias.index_select(0, kk)\n",
    "        # b is whether a random number is greater than q\n",
    "        b = torch.bernoulli(prob)\n",
    "        oq = kk.mul(b.long()) # mul 按元素相乘\n",
    "        oj = alias.mul((1-b).long())\n",
    "\n",
    "        return oq + oj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daecf979-bd4a-48ff-909c-d62da8f4df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # 创建一个包含概率的张量\n",
    "# prob = torch.tensor([0.2, 0.5, 0.8, 0.0, 1.0])\n",
    "\n",
    "# # 使用 torch.bernoulli 生成伯努利随机数\n",
    "# samples = torch.bernoulli(prob) \n",
    "# # 这个函数根据给定的概率值 prob，为每个元素生成一个随机数，如果该位置上的概率值大于或等于生成的随机数，则返回 1，否则返回 0。\n",
    "# # 生成的 1 的概率与 prob 中对应的值相同，生成 0 的概率则为 1 - prob。\n",
    "# print(\"Probability tensor:\", prob)\n",
    "# print(\"Bernoulli samples:\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bdccf-e381-4820-98d8-7878099eb59c",
   "metadata": {},
   "source": [
    "这段代码实现了 `Alias Method`，一种高效的多项分布采样方法，特别适用于具有大量离散结果的情况。它的作用是以 \\(O(1)\\) 的时间复杂度从给定的概率分布中采样。代码中定义了 `AliasMethod` 类，该类可以基于输入的概率分布生成样本。\r\n",
    "\r\n",
    "### 逐行解释代码\r\n",
    "\r\n",
    "```python\r\n",
    "class AliasMethod(object):\r\n",
    "    '''\r\n",
    "        From: https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\r\n",
    "    '''\r\n",
    "```\r\n",
    "- 定义了一个 `AliasMethod` 类，该类用于实现 `Alias Method` 采样算法。注释中提供了参考资料的链接。\r\n",
    "\r\n",
    "```python\r\n",
    "def __init__(self, probs):\r\n",
    "```\r\n",
    "- 定义了类的构造函数 `__init__`，接收一个概率分布 `probs` 作为输入参数。\r\n",
    "\r\n",
    "```python\r\n",
    "if probs.sum() > 1:\r\n",
    "    probs.div_(probs.sum())\r\n",
    "```\r\n",
    "- 如果输入的概率分布 `probs` 的和大于1，将 `probs` 归一化，使其和为1。`div_` 是一个原地操作（in-place operation），会直接修改 `probs`。\r\n",
    "\r\n",
    "```python\r\n",
    "K = len(probs)\r\n",
    "self.prob = torch.zeros(K)\r\n",
    "self.alias = torch.LongTensor([0]*K)\r\n",
    "```\r\n",
    "- 计算概率分布 `probs` 的长度 `K`，即离散事件的数量。初始化两个 `torch.Tensor` 对象：`self.prob` 用于存储归一化后的概率值，`self.alias` 用于存储“别名”索引，分别分配给 `K` 个事件。\r\n",
    "\r\n",
    "```python\r\n",
    "smaller = []\r\n",
    "larger = []\r\n",
    "```\r\n",
    "- 初始化两个列表 `smaller` 和 `larger`，用于分别存储小于和大于 \\( \\frac{1}{K} \\) 的概率的事件索引。\r\n",
    "\r\n",
    "```python\r\n",
    "for kk, prob in enumerate(probs):\r\n",
    "    self.prob[kk] = K*prob\r\n",
    "    if self.prob[kk] < 1.0:\r\n",
    "        smaller.append(kk)\r\n",
    "    else:\r\n",
    "        larger.append(kk)\r\n",
    "```\r\n",
    "- 遍历 `probs`，将每个概率 `prob` 乘以 `K` 后存入 `self.prob` 中。如果处理后的概率小于 1.0，将对应索引加入 `smaller` 列表，否则加入 `larger` 列表。\r\n",
    "\r\n",
    "```python\r\n",
    "while len(smaller) > 0 and len(larger) > 0:\r\n",
    "    small = smaller.pop()\r\n",
    "    large = larger.pop()\r\n",
    "\r\n",
    "    self.alias[small] = large\r\n",
    "    self.prob[large] = (self.prob[large] - 1.0) + self.prob[small]\r\n",
    "\r\n",
    "    if self.prob[large] < 1.0:\r\n",
    "        smaller.append(large)\r\n",
    "    else:\r\n",
    "        larger.append(large)\r\n",
    "```\r\n",
    "- 在 `smaller` 和 `larger` 列表都不为空时，循环执行以下步骤：\r\n",
    "  - 从 `smaller` 和 `larger` 中各取出一个索引 `small` 和 `large`。\r\n",
    "  - 将 `large` 的索引存储到 `self.alias[small]` 中，即为 `small` 创建“别名”。\r\n",
    "  - 调整 `large` 对应的概率值，使其减去 `1.0` 并加上 `small` 对应的概率值。\r\n",
    "  - 根据调整后的概率值决定将 `large` 重新加入 `smaller` 或 `larger`。\r\n",
    "\r\n",
    "```python\r\n",
    "for last_one in smaller+larger:\r\n",
    "    self.prob[last_one] = 1\r\n",
    "```\r\n",
    "- 将 `smaller` 和 `larger` 列表中剩下的索引对应的 `self.prob` 值设为 1.0。这是为了处理剩余的概率，确保每个事件都有合适的概率值。\r\n",
    "\r\n",
    "```python\r\n",
    "def cuda(self): \r\n",
    "    self.prob = self.prob.cuda()\r\n",
    "    self.alias = self.alias.cuda()\r\n",
    "```\r\n",
    "- 定义了 `cuda` 方法，用于将 `self.prob` 和 `self.alias` 两个张量移动到 GPU 上，以加速计算。\r\n",
    "\r\n",
    "```python\r\n",
    "def draw(self, N):\r\n",
    "    '''\r\n",
    "        Draw N samples from multinomial\r\n",
    "    '''\r\n",
    "    K = self.alias.size(0)\r\n",
    "```\r\n",
    "- 定义 `draw` 方法，用于从多项分布中抽取 `N` 个样本。首先，获取 `self.alias` 的大小 `K`。\r\n",
    "\r\n",
    "```python\r\n",
    "kk = torch.zeros(N, dtype=torch.long, device=self.prob.device).random_(0, K)\r\n",
    "prob = self.prob.index_select(0, kk)\r\n",
    "alias = self.alias.index_select(0, kk)\r\n",
    "```\r\n",
    "- 生成 `N` 个随机索引 `kk`，这些索引指向 `self.prob` 和 `self.alias` 中的元素。`prob` 和 `alias` 分别选择 `kk` 索引指向的 `self.prob` 和 `self.alias` 中的值。\r\n",
    "\r\n",
    "```python\r\n",
    "b = torch.bernoulli(prob)\r\n",
    "oq = kk.mul(b.long())\r\n",
    "oj = alias.mul((1-b).long())\r\n",
    "```\r\n",
    "- 对每个 `prob` 生成一个伯努利随机数 `b`。然后根据 `b` 的值，确定使用原索引 `kk` 还是“别名”索引 `alias`。\r\n",
    "\r\n",
    "```python\r\n",
    "return oq + oj\r\n",
    "```\r\n",
    "- 返回最终的索引值，这些索引对应于从给定概率分布中采样得到的结果。\r\n",
    "\r\n",
    "### 总结：\r\n",
    "这段代码实现了 `Alias Method`，这是一个用于高效从离散分布中采样的算法。通过使用 `prob` 和 `alias` 表，可以在 \\(O(1)\\) 时间内生成样本。`cuda` 方法允许在 GPU 上执行操作，而 `draw` 方法用于实际进行采样。\r\n",
    "\r\n",
    "**a.** 是否需要展示一个使用 `AliasMethod` 类生成样本的具体实例？  \r\n",
    "**b.** 是否需要解释如何应用此类在特定任务中，如生成模型或其他概率分布采样任务？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce53730e-04df-40ce-b637-74700512fa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "import torch\n",
    "\n",
    "memory = torch.randn(100, 64)  # 假设 memory bank 有 100 个样本，每个样本的特征维度为 64\n",
    "idx = torch.tensor([\n",
    "    [10, 20, 30],  # 第一个样本：正样本索引为 10，负样本索引为 20 和 30\n",
    "    [40, 50, 60],  # 第二个样本：正样本索引为 40，负样本索引为 50 和 60\n",
    "    [70, 80, 90],  # 第三个样本：正样本索引为 70，负样本索引为 80 和 90\n",
    "    [ 0,  1,  2]   # 第四个样本：正样本索引为  0，负样本索引为  1 和  2\n",
    "])\n",
    "weight = torch.index_select(memory, 0, idx.view(-1)) # 从memory中挑选指定的行\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1855d385-0650-4502-8313-3c2020a8403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch import nn\n",
    "# from .alias_multinomial import AliasMethod\n",
    "import math\n",
    "\n",
    "class NCEFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x, y, memory, idx, params): # features.shape=(batch_size, feature_size), indexes.shape=torch.Size([128]), memory bank, idx.shape(128,4097), params\n",
    "        K = int(params[0].item())  # 负样本的数量\n",
    "        T = params[1].item()  # 温度参数\n",
    "        Z = params[2].item()  # 归一化常数\n",
    "        momentum = params[3].item()  # 动量参数\n",
    "        batchSize = x.size(0)  # 当前批次的大小\n",
    "        outputSize = memory.size(0)  # memory bank 的大小\n",
    "        inputSize = memory.size(1)  # 输入特征的维度\n",
    "\n",
    "        # sample positives & negatives\n",
    "        idx.select(1,0).copy_(y.data) # 将正样本索引放入 idx 的第一列，这样idx的第一列就都是正样本，后面4096个都是负样本\n",
    "\n",
    "        # 采样相应的特征向量（正样本和负样本）\n",
    "        weight = torch.index_select(memory, 0, idx.view(-1)) # 从memory中提取出所有第0维（行），再按照idx.view(-1)的索引提取出指定的行 - (len(idx.view(-1)), inputSize)\n",
    "        # 感觉也不能说是weights吧，许多images的特征，用features似乎更合适一点\n",
    "        weight.resize_(batchSize, K+1, inputSize) # resize成跟idx一样的shape - (batchSize, K+1, inputSize) - (128, 4097, 128)\n",
    "\n",
    "        # inner product\n",
    "        out = torch.bmm(weight, x.data.resize_(batchSize, inputSize, 1)) # x.shape=(128,128), 所以这里的out就是(128, 4097, 1)，每个正样本和4097个样本（一正4096副）的内积\n",
    "        # 非参数softmax\n",
    "        # print(\"1\", out)\n",
    "        out.div_(T).exp_() # batchSize * self.K+1\n",
    "        # print(\"2\", out)\n",
    "        x.data.resize_(batchSize, inputSize)\n",
    "\n",
    "        if Z < 0: # Z 的设置: 如果 Z 小于 0，表示还没有初始化，因此在第一次计算时设置 Z 的值 - Z就是非参数softmax的分母\n",
    "            params[2] = out.mean() * outputSize # out.mean()生成单个数\n",
    "            Z = params[2].item() \n",
    "            print(\"normalization constant Z is set to {:.1f}\".format(Z))\n",
    "\n",
    "        out.div_(Z).resize_(batchSize, K+1) # 从(batchSize, K+1, 1) -> (batchSize, K+1)\n",
    "\n",
    "        # 保存用于反向传播的张量\n",
    "        self.save_for_backward(x, memory, y, weight, out, params)\n",
    "\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, gradOutput):\n",
    "        x, memory, y, weight, out, params = self.saved_tensors\n",
    "        K = int(params[0].item())\n",
    "        T = params[1].item()\n",
    "        Z = params[2].item()\n",
    "        momentum = params[3].item()\n",
    "        batchSize = gradOutput.size(0)\n",
    "        \n",
    "        # gradients d Pm / d linear = exp(linear) / Z????????? # 此时开始更新特征v，原文中equation2\n",
    "        gradOutput.data.mul_(out.data) # out.shape=(batchSize, K+1) # 应该是有一个近似，具体看平板\n",
    "        # add temperature # d exp(linear) / d (v_i)^T v = (1/T) * exp((v_i)^T v)\n",
    "        gradOutput.data.div_(T)\n",
    "\n",
    "        gradOutput.data.resize_(batchSize, 1, K+1)\n",
    "        \n",
    "        # gradient of linear \n",
    "        # print(gradOutput.shape, weight.shape) # torch.Size([128, 4097]) torch.Size([128, 4097, 128])\n",
    "        gradOutput = gradOutput.reshape(batchSize, 1, K+1) # 这一步源代码中没有\n",
    "        # d exp((v_i)^T v) / d v_i = exp((v_i)^T v) * v 吗？？？？？？？？？\n",
    "        # \\exp((v_i)^T v) \\) 对 \\( v_i \\) 的导数是 exp(v_i^T v) \\cdot v - GPT\n",
    "        # v就是weight - 果然有近似\n",
    "        gradInput = torch.bmm(gradOutput.data, weight) # (batchSize, 1, K+1) mm (batchSize, K+1, inputSize) -> (batchSize, 1, inputSize)\n",
    "        gradInput.resize_as_(x) # x.shape=(batch_size, feature_size=inputSize)\n",
    "\n",
    "        # update the non-parametric data - 更新memory bank中的特征v\n",
    "        # weight.shape =(batchSize, K+1, inputSize)\n",
    "        weight_pos = weight.select(1, 0).resize_as_(x) # 见下面的test - (batchSize, inputSize) 及所有批次的第一个样本的特征，及所有正样本的特征\n",
    "        weight_pos.mul_(momentum)\n",
    "        weight_pos.add_(torch.mul(x.data, 1-momentum)) # v_i' = \\text{momentum} \\cdot v_i + (1 - \\text{momentum}) \\cdot x\n",
    "        w_norm = weight_pos.pow(2).sum(1, keepdim=True).pow(0.5)\n",
    "        updated_weight = weight_pos.div(w_norm) # 将更新后的向量归一化，确保它的模为 1\n",
    "        memory.index_copy_(0, y, updated_weight)\n",
    "        \n",
    "        return gradInput, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e036e0e3-575a-435c-b8ca-b095757737c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 6]), torch.Size([4, 6]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "import torch\n",
    "\n",
    "batchSize = 4\n",
    "K = 6\n",
    "inputSize = 6\n",
    "\n",
    "weight = torch.randn(2, 2, 2)  # 初始形状为 (2, 2, 2)\n",
    "weight.resize_(batchSize, K+1, inputSize)  # 调整形状为 (4, 7, 6)\n",
    "selected_weight = weight.select(1, 0)\n",
    "weight.shape, selected_weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257e069-c7d4-4a79-987e-3e2428836631",
   "metadata": {},
   "source": [
    "对于给定的函数 $P(i|v) = \\dfrac{\\exp\\left(\\frac{v_i^T v}{t}\\right)}{\\sum_{j=1}^n \\exp\\left(\\frac{v_j^T v}{t}\\right)}$，我们对 \\( v_i \\) 求导。这里 \\( t \\) 是一个常数，称为温度参数。\n",
    "\n",
    "我们可以将这个过程分为以下几个步骤：\n",
    "\n",
    "### 步骤 1: 定义函数\n",
    "首先，我们可以将 \\( P(i|v) \\) 写成两部分的比值：\n",
    "\n",
    "$$\n",
    "P(i|v) = \\frac{A_i}{B}\n",
    "$#\n",
    "\n",
    "其中：\n",
    "\n",
    "$$\n",
    "A_i = \\exp\\left(\\frac{v_i^T v}{t}\\right)\n",
    "$$\n",
    "$$\n",
    "B = \\sum_{j=1}^n \\exp\\left(\\frac{v_j^T v}{t}\\right)\n",
    "$$\n",
    "\n",
    "### 步骤 2: 对 \\( A_i \\) 求导\n",
    "对 \\( A_i \\) 关于 \\( v_i \\) 求导：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial A_i}{\\partial v_i} = \\frac{1}{t} \\exp\\left(\\frac{v_i^T v}{t}\\right) \\cdot v = \\frac{1}{t} A_i \\cdot v\n",
    "$$\n",
    "\n",
    "### 步骤 3: 对 \\( B \\) 求导\n",
    "对 \\( B \\) 关于 \\( v_i \\) 求导：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial B}{\\partial v_i} = \\frac{\\partial}{\\partial v_i} \\left(\\sum_{j=1}^n \\exp\\left(\\frac{v_j^T v}{t}\\right)\\right)\n",
    "$$\n",
    "\n",
    "注意到 \\( B \\) 是 \\( n \\) 项之和，其中只有第 \\( i \\) 项包含 \\( v_i \\)。因此，导数为：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial B}{\\partial v_i} = \\frac{1}{t} \\exp\\left(\\frac{v_i^T v}{t}\\right) \\cdot v = \\frac{1}{t} A_i \\cdot v\n",
    "$$\n",
    "\n",
    "### 步骤 4: 使用商的求导法则\n",
    "使用商的求导法则（Quotient Rule），对 \\( P(i|v) = \\frac{A_i}{B} \\) 关于 \\( v_i \\) 求导：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial P(i|v)}{\\partial v_i} = \\frac{\\partial \\left(\\frac{A_i}{B}\\right)}{\\partial v_i} = \\frac{\\frac{\\partial A_i}{\\partial v_i} \\cdot B - A_i \\cdot \\frac{\\partial B}{\\partial v_i}}{B^2}\n",
    "$$\n",
    "\n",
    "将前面计算的 \\( \\frac{\\partial A_i}{\\partial v_i} \\) 和 \\( \\frac{\\partial B}{\\partial v_i} \\) 代入：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial P(i|v)}{\\partial v_i} = \\frac{\\left(\\frac{1}{t} A_i \\cdot v\\right) \\cdot B - A_i \\cdot \\left(\\frac{1}{t} A_i \\cdot v\\right)}{B^2}\n",
    "$$\n",
    "\n",
    "### 步骤 5: 化简表达式\n",
    "进一步化简这个表达式：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial P(i|v)}{\\partial v_i} = \\frac{\\frac{1}{t} A_i \\cdot v \\cdot B - \\frac{1}{t} A_i^2 \\cdot v}{B^2} = \\frac{A_i \\cdot v}{t} \\cdot \\frac{B - A_i}{B^2}\n",
    "$$\n",
    "\n",
    "等价于\n",
    "\n",
    "$$\n",
    "\\frac{\\partial P(i|v)}{\\partial v_i} = \\frac{\\frac{1}{t} A_i \\cdot v \\cdot B - \\frac{1}{t} A_i^2 \\cdot v}{B^2} = \\frac{A_i}{B} \\cdot \\frac{1}{t} \\cdot v \\cdot \\frac{B - A_i}{B}\n",
    "$$\n",
    "\n",
    "注意到 \\( P(i|v) = \\frac{A_i}{B} \\)，所以可以将表达式重新整理为：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial P(i|v)}{\\partial v_i} = P(i|v) \\cdot \\frac{v}{t} \\cdot \\left(1 - P(i|v)\\right)\n",
    "$$\n",
    "\n",
    "### 最终结果\n",
    "所以，对 \\( P(i|v) \\) 关于 \\( v_i \\) 的导数为：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial P(i|v)}{\\partial v_i} = P(i|v) \\cdot \\frac{v}{t} \\cdot \\left(1 - P(i|v)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "551913cf-506f-4f02-8561-355ecb166793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCEAverage(nn.Module):\n",
    "\n",
    "    def __init__(self, inputSize, outputSize, K, T=0.07, momentum=0.5, Z=None):\n",
    "        super(NCEAverage, self).__init__()\n",
    "        self.nLem = outputSize\n",
    "        self.unigrams = torch.ones(self.nLem)\n",
    "        self.multinomial = AliasMethod(self.unigrams)\n",
    "        self.multinomial.cuda()\n",
    "        self.K = K\n",
    "\n",
    "        self.register_buffer('params',torch.tensor([K, T, -1, momentum]));\n",
    "        stdv = 1. / math.sqrt(inputSize/3)\n",
    "        self.register_buffer('memory', torch.rand(outputSize, inputSize).mul_(2*stdv).add_(-stdv))\n",
    " \n",
    "    def forward(self, x, y): # lemniscate(features, indexes); x - (batch_size, feature_size); y - (batch_size)\n",
    "        batchSize = x.size(0)\n",
    "        idx = self.multinomial.draw(batchSize * (self.K+1)).view(batchSize, -1)\n",
    "        # print(\"!!!\", idx.shape, idx) # torch.Size([128, 4097])\n",
    "        out = NCEFunction.apply(x, y, self.memory, idx, self.params)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "355a70d3-f069-4084-899b-e8306e88e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCECriterion(nn.Module):\n",
    "    def __init__(self, nLem):\n",
    "        super(NCECriterion, self).__init__()\n",
    "        self.nLem = nLem\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        batchSize = x.size(0)\n",
    "        K = x.size(1) - 1\n",
    "        Pnt = 1 / float(self.nLem)\n",
    "        Pns = 1 / float(self.nLem)\n",
    "\n",
    "        Pmt = x.select(1, 0)\n",
    "        Pmt_div = Pmt.add(K * Pnt + 1e-7)\n",
    "        lnPmt = torch.div(Pmt, Pmt_div)\n",
    "\n",
    "        Pon_div = x.narrow(1, 1, K).add(K * Pns + 1e-7)\n",
    "        # print(\"###########################\", Pon_div)\n",
    "        Pon = Pon_div.clone().fill_(K * Pns)\n",
    "        lnPon = torch.div(Pon, Pon_div)\n",
    "\n",
    "        lnPmt.log_()\n",
    "        lnPon.log_()\n",
    "\n",
    "        lnPmtsum = lnPmt.sum(0)\n",
    "        lnPonsum = lnPon.view(-1, 1).sum(0)\n",
    "\n",
    "        ######################################################\n",
    "        print(\"###\", lnPmtsum.item(), lnPonsum.item(), \"###\",)\n",
    "        loss = - (lnPmtsum + lnPonsum) / batchSize\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "555c55e5-1971-4ec3-8d41-bc5395902015",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0\n",
    "start_epoch = 0\n",
    "low_dim = 128\n",
    "nce_k = 4096 # defult 4096\n",
    "nce_t = 0.5 # 温度\n",
    "nce_m = 0.5 # SGD 动量参数\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb67076c-9f88-49df-8d43-e51ef2de9a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n",
    "    # transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# d2l-zh/pytorch/MyExercises/data\n",
    "trainset = CIFAR10Instance(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = CIFAR10Instance(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "ndata = len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a87a010-2d59-4d13-89bd-bb2c6ad4800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32]) torch.Size([128]) torch.Size([128])\n",
      "tensor([3, 0, 6, 2, 3, 5, 7, 5, 7, 3, 8, 6, 1, 6, 8, 0, 2, 8, 7, 7, 2, 9, 9, 8,\n",
      "        5, 8, 0, 2, 9, 7, 6, 3, 5, 1, 6, 1, 2, 9, 8, 5, 6, 1, 7, 7, 7, 3, 3, 0,\n",
      "        6, 0, 7, 9, 6, 5, 4, 0, 4, 3, 6, 8, 8, 2, 6, 2, 0, 0, 9, 1, 9, 1, 6, 6,\n",
      "        3, 4, 1, 4, 1, 0, 1, 1, 9, 5, 6, 5, 1, 7, 2, 3, 3, 0, 6, 5, 2, 7, 8, 1,\n",
      "        1, 1, 2, 1, 7, 5, 2, 2, 2, 6, 9, 4, 7, 4, 8, 5, 3, 3, 9, 1, 5, 1, 3, 8,\n",
      "        0, 4, 0, 5, 5, 5, 5, 1]) tensor([47683, 35798, 42358, 27738, 38423, 19606, 21718,  3896,  2977, 28330,\n",
      "        31354, 42762, 17726,   488, 37794, 44666,  3558, 49985, 39962, 15045,\n",
      "        30470, 34502, 47944,   328, 42317, 43846, 15992, 17859, 22160, 40199,\n",
      "        43977,  6167, 35609, 24540, 20548, 29264, 48364, 34474, 38495, 26221,\n",
      "        44862, 47532, 18524, 25788,  3782, 38100,  8302, 39372, 13046, 47862,\n",
      "        10887, 13529, 49459, 12322,  5950, 41762, 11927,  1534, 37825, 45937,\n",
      "         7447, 42430, 35349, 22835,  4061, 43548, 48313,  6456, 41267, 32827,\n",
      "        37221,  1537, 19727, 36764, 19185,   660,  2582, 44045, 46906, 47836,\n",
      "        37050,  4424, 20384, 10780,   568,  5782, 33649, 45362, 27304, 28092,\n",
      "        14628, 31995, 11538, 10339, 21812, 49362, 43205, 23477, 35243, 15632,\n",
      "        10502, 26676, 15788, 19236, 33293, 36808, 20420, 29086, 45276, 49598,\n",
      "        45578, 26920,  4847, 26964, 10448, 15704, 28147, 40090, 30022, 12443,\n",
      "        17174, 35187,  2427, 32364,  6037,  9746, 28595, 21829])\n"
     ]
    }
   ],
   "source": [
    "for img, target, index in trainloader:\n",
    "    print(img.shape, target.shape, index.shape)\n",
    "    print(target, index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cd7303e-e811-43b3-bede-b68bbcec9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model..')\n",
    "net = torchvision.models.resnet18(num_classes=low_dim)  # Using ResNet18 with the low_dim output\n",
    "lemniscate = NCEAverage(low_dim, ndata, nce_k, nce_t, nce_m)\n",
    "\n",
    "# if device == 'cuda':\n",
    "#     net = nn.DataParallel(net).to(device)\n",
    "#     cudnn.benchmark = True\n",
    "net.to(device)\n",
    "lemniscate.to(device)\n",
    "\n",
    "criterion = NCECriterion(ndata).to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c3877a4-be3e-4404-83c7-96c7477ee604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 80 epochs\"\"\"\n",
    "    lr = learning_rate\n",
    "    if epoch >= 80:\n",
    "        lr *= 0.1 ** ((epoch - 80) // 40)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2651981-673e-437d-923c-7d37bbcd8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    net.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    for batch_idx, (inputs, targets, indexes) in enumerate(trainloader):\n",
    "        inputs, targets, indexes = inputs.to(device), targets.to(device), indexes.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        features = net(inputs)\n",
    "        outputs = lemniscate(features, indexes)\n",
    "        # print(\"###\", outputs)\n",
    "        loss = criterion(outputs, indexes)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        # if batch_idx % 100 == 0:\n",
    "        #     print(f'Batch {batch_idx}/{len(trainloader)}: Loss: {loss.item():.4f}')\n",
    "        print(f'Batch {batch_idx}/{len(trainloader)}: Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48d061cf-51f1-40e6-bfa7-25f9220dcf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    acc = kNN(epoch, net, lemniscate, trainloader, testloader, 200, nce_t, 0)\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'lemniscate': lemniscate,\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "\n",
    "    print(f'Best Accuracy: {best_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39ca3a6a-2553-43e7-ab29-4644861fd10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "!!! torch.Size([128, 4097]) tensor([[12761, 11460, 37707,  ..., 37701, 40144, 23955],\n",
      "        [ 2290, 38044, 42255,  ...,   867, 18125, 40281],\n",
      "        [ 3224,  8357, 39445,  ..., 22418, 14691, 19997],\n",
      "        ...,\n",
      "        [12396,  1240,  2812,  ..., 41168, 36731,  6092],\n",
      "        [28842, 24197, 28147,  ...,   856, 48454, 36326],\n",
      "        [20814, 20352, 22697,  ...,  8676, 32199, 28002]], device='cuda:0')\n",
      "normalization constant Z is set to 468620.3\n",
      "### -20.558202743530273 -1399154.625 ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\envs\\DL_learning\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/391: Loss: 10931.0557\n",
      "!!! torch.Size([128, 4097]) tensor([[38224,  5225,  9649,  ..., 34618, 36665, 36075],\n",
      "        [14722, 12921, 11367,  ..., 47293, 32154, 13240],\n",
      "        [  737, 19829, 27042,  ..., 23334, 26988, 40643],\n",
      "        ...,\n",
      "        [28256, 48599, 48520,  ..., 20615, 40464, 30319],\n",
      "        [18862, 16471, 37304,  ..., 31582, 26305,  6677],\n",
      "        [47730, 39393, 14373,  ...,  1060,  3899,  6174]], device='cuda:0')\n",
      "### -19.122356414794922 -1386965.5 ###\n",
      "Batch 1/391: Loss: 10835.8174\n",
      "!!! torch.Size([128, 4097]) tensor([[10826,  7770, 30710,  ..., 25617, 34360, 40258],\n",
      "        [27569,  7970, 38160,  ...,  6285, 15770, 36488],\n",
      "        [26563, 32438, 39972,  ..., 48145,  2610, 18192],\n",
      "        ...,\n",
      "        [21042, 25809,  1394,  ...,  9848, 31683, 20836],\n",
      "        [37446, 18136, 26267,  ...,  4381,   893, 32090],\n",
      "        [29987,  9836,  3664,  ..., 10781, 22997, 33439]], device='cuda:0')\n",
      "### -19.568439483642578 -1372033.75 ###\n",
      "Batch 2/391: Loss: 10719.1670\n",
      "!!! torch.Size([128, 4097]) tensor([[21034, 28812, 25165,  ..., 20277,  4078,  1132],\n",
      "        [22300, 29334, 26316,  ..., 31632, 29061, 42327],\n",
      "        [33979, 48401,  9292,  ..., 45389,  2700, 13838],\n",
      "        ...,\n",
      "        [43128, 15272, 40136,  ..., 21733, 39809,  8460],\n",
      "        [32748,  2207, 43201,  ..., 22395, 47888,  5077],\n",
      "        [ 3408, 18553, 28680,  ..., 32677,  8048, 34640]], device='cuda:0')\n",
      "### -26.75991439819336 -1386113.0 ###\n",
      "Batch 3/391: Loss: 10829.2168\n",
      "!!! torch.Size([128, 4097]) tensor([[25631, 23206, 37257,  ..., 17101, 30616, 34499],\n",
      "        [ 4004, 46668, 30234,  ...,  8313, 47246,  1876],\n",
      "        [14475, 11029, 23098,  ..., 36507,  8581, 42701],\n",
      "        ...,\n",
      "        [ 1420, 11742, 17845,  ..., 14204, 35327,  3681],\n",
      "        [38663,  9760, 40536,  ..., 39909, 25249,   994],\n",
      "        [45828, 36445,  9219,  ...,  3171,  5200, 10270]], device='cuda:0')\n",
      "### -26.992942810058594 -1408099.0 ###\n",
      "Batch 4/391: Loss: 11000.9844\n",
      "!!! torch.Size([128, 4097]) tensor([[12528, 29767, 35160,  ..., 37091, 46486, 26476],\n",
      "        [17510, 19778, 34263,  ..., 42541, 45976, 10645],\n",
      "        [37834, 12383,  6851,  ..., 35910, 19593, 26318],\n",
      "        ...,\n",
      "        [45059, 19293, 23866,  ..., 18781, 34195, 49516],\n",
      "        [29968, 32645, 18741,  ...,  6653,  4960, 32452],\n",
      "        [25323, 10362,  5132,  ..., 49954, 35559,  4224]], device='cuda:0')\n",
      "### -23.709259033203125 -1402812.5 ###\n",
      "Batch 5/391: Loss: 10959.6582\n",
      "!!! torch.Size([128, 4097]) tensor([[ 7105, 39077, 24548,  ..., 27315, 40807, 11201],\n",
      "        [22324, 48101, 23073,  ..., 25728, 41783, 12312],\n",
      "        [33779, 48192,  5807,  ..., 46935, 27298, 18077],\n",
      "        ...,\n",
      "        [30722,  2294,  2382,  ..., 40938,   385, 14481],\n",
      "        [22470, 46152, 26989,  ..., 23426,   497, 44590],\n",
      "        [14922, 47710,  4059,  ..., 25597,  5242,  3744]], device='cuda:0')\n",
      "### -14.344276428222656 -1377161.0 ###\n",
      "Batch 6/391: Loss: 10759.1826\n",
      "!!! torch.Size([128, 4097]) tensor([[34594, 43775, 32691,  ..., 37882, 16639, 17050],\n",
      "        [34524, 10396,  9386,  ..., 25945, 45867, 31812],\n",
      "        [15671, 48574, 14991,  ..., 11741, 34427,  8985],\n",
      "        ...,\n",
      "        [27184,  9823, 45693,  ...,  4896, 42197, 12355],\n",
      "        [45155,  9302, 25660,  ..., 17303,  8636,  2599],\n",
      "        [16141, 49010, 41472,  ..., 24738, 25691,  1582]], device='cuda:0')\n",
      "### -16.49017906188965 -1376392.25 ###\n",
      "Batch 7/391: Loss: 10753.1934\n",
      "!!! torch.Size([128, 4097]) tensor([[43231, 22345,  3029,  ...,  5363, 37665, 39276],\n",
      "        [23345, 28582, 42232,  ..., 47244,   599, 23130],\n",
      "        [44227, 33711, 12387,  ...,  1209, 34131,  3814],\n",
      "        ...,\n",
      "        [12767,   212, 47922,  ..., 19316, 14678,  2579],\n",
      "        [10400, 47490,  7310,  ..., 15937, 17834, 18758],\n",
      "        [47168, 39290, 28061,  ...,   596, 49488, 23971]], device='cuda:0')\n",
      "### -16.23844337463379 -1404134.75 ###\n",
      "Batch 8/391: Loss: 10969.9297\n",
      "!!! torch.Size([128, 4097]) tensor([[24546, 21822,  5104,  ..., 19439, 35241, 20638],\n",
      "        [32905, 37256,   406,  ..., 26738,  5971, 24221],\n",
      "        [49037, 48151, 48751,  ..., 13347, 34030, 41649],\n",
      "        ...,\n",
      "        [26345, 35424, 11498,  ..., 26215, 46989, 15858],\n",
      "        [32006, 36746, 30363,  ...,  9014, 15392, 37383],\n",
      "        [ 2767,  7326, 27172,  ..., 43338,  9112, 39779]], device='cuda:0')\n",
      "### -14.7362060546875 -1400489.5 ###\n",
      "Batch 9/391: Loss: 10941.4395\n",
      "!!! torch.Size([128, 4097]) tensor([[18077,  6030, 47044,  ..., 25220, 29049, 43510],\n",
      "        [ 3578, 25725, 40198,  ..., 23946, 38472,   340],\n",
      "        [21755,  2448,  1182,  ..., 14646, 10672, 26628],\n",
      "        ...,\n",
      "        [44492, 12009, 44710,  ...,    17, 37691, 30984],\n",
      "        [29434, 19077, 10011,  ..., 35193, 10173, 34349],\n",
      "        [45022, 33156, 21637,  ..., 17347,  4053, 41917]], device='cuda:0')\n",
      "### -13.001296043395996 -1368816.75 ###\n",
      "Batch 10/391: Loss: 10693.9824\n",
      "!!! torch.Size([128, 4097]) tensor([[32580, 44206, 33911,  ..., 16034, 12496, 24451],\n",
      "        [26487, 40582, 12391,  ..., 42546, 15077,  5850],\n",
      "        [ 5112, 27373, 29468,  ..., 26524, 39972, 49875],\n",
      "        ...,\n",
      "        [19985, 31752, 37049,  ...,  8275, 33666, 16723],\n",
      "        [42097, 20402,  5216,  ..., 29750, 30748, 46550],\n",
      "        [22331, 39274,    73,  ...,  7518, 42489,  9514]], device='cuda:0')\n",
      "### -11.751701354980469 -1366139.25 ###\n",
      "Batch 11/391: Loss: 10673.0547\n",
      "!!! torch.Size([128, 4097]) tensor([[ 6556, 19405,    58,  ..., 24298, 19540,  3466],\n",
      "        [45067, 33766, 10329,  ...,  2794,  4347, 29617],\n",
      "        [10847,  4321, 49165,  ..., 27449, 12810, 45350],\n",
      "        ...,\n",
      "        [33025,  9890, 34560,  ..., 29016, 22906, 39027],\n",
      "        [ 1967, 45270, 44215,  ..., 35723, 25817,  2671],\n",
      "        [26439,  3607,  3403,  ..., 30627,  1222, 37759]], device='cuda:0')\n",
      "### -15.71653938293457 -1391774.5 ###\n",
      "Batch 12/391: Loss: 10873.3613\n",
      "!!! torch.Size([128, 4097]) tensor([[28717, 26750, 27954,  ...,  4386,  9261, 43780],\n",
      "        [ 4398, 46020, 24618,  ..., 22801,  4214, 48718],\n",
      "        [ 7413, 36621, 21174,  ..., 41012, 42831, 16705],\n",
      "        ...,\n",
      "        [14326, 46754, 10202,  ..., 37848, 43430, 40438],\n",
      "        [ 5231,  1997, 43167,  ..., 13652, 27781, 45489],\n",
      "        [41243, 42941,    39,  ..., 45654, 46159, 47760]], device='cuda:0')\n",
      "### -13.51017951965332 -1396827.625 ###\n",
      "Batch 13/391: Loss: 10912.8213\n",
      "!!! torch.Size([128, 4097]) tensor([[15727,   149, 38368,  ..., 30657, 31532, 31539],\n",
      "        [17476,  8248,  3664,  ..., 32322, 10276, 38188],\n",
      "        [41196,  1159, 28622,  ..., 17434, 16347,  8709],\n",
      "        ...,\n",
      "        [   55, 10976, 34377,  ..., 11362, 16953, 38363],\n",
      "        [35775,  9435, 16678,  ...,  4311, 13418, 12810],\n",
      "        [22999,   428, 27360,  ..., 30040, 23875, 43468]], device='cuda:0')\n",
      "### -12.28758430480957 -1374977.5 ###\n",
      "Batch 14/391: Loss: 10742.1074\n",
      "!!! torch.Size([128, 4097]) tensor([[41836, 12126, 15475,  ..., 46964,  4423, 46238],\n",
      "        [40341, 29025,  1923,  ...,  3570, 25134,  2057],\n",
      "        [18057, 12280, 46000,  ...,  2633,  9484, 30894],\n",
      "        ...,\n",
      "        [ 5070, 46683,  8216,  ..., 31323, 42627,  8579],\n",
      "        [13003, 22094, 29263,  ...,  4728, 12214, 18004],\n",
      "        [18122, 40009, 18816,  ...,  6187,  3982, 38495]], device='cuda:0')\n",
      "### -11.273818969726562 -1356896.5 ###\n",
      "Batch 15/391: Loss: 10600.8418\n",
      "!!! torch.Size([128, 4097]) tensor([[26507, 27385, 47657,  ...,  4731, 40067,  5668],\n",
      "        [30215, 13444, 37249,  ..., 12480, 46235, 44776],\n",
      "        [22258,  5212, 46254,  ..., 12991,  3617, 26062],\n",
      "        ...,\n",
      "        [  212, 43509, 15113,  ..., 46398, 48885, 22542],\n",
      "        [48723, 19105, 12456,  ..., 15183, 25140, 48529],\n",
      "        [11679, 33626, 47152,  ..., 34732, 15982, 12697]], device='cuda:0')\n",
      "### -13.828248977661133 -1368109.875 ###\n",
      "Batch 16/391: Loss: 10688.4668\n",
      "!!! torch.Size([128, 4097]) tensor([[20789, 37404, 26345,  ...,  8767, 13520, 42521],\n",
      "        [29824,  7014, 21999,  ..., 17474, 42413,  7887],\n",
      "        [12225, 36652, 44354,  ..., 30224, 21352, 32751],\n",
      "        ...,\n",
      "        [32735, 37454, 18051,  ..., 36742, 36897, 22045],\n",
      "        [28647, 18313, 38748,  ...,  2916,  6026, 23948],\n",
      "        [25154, 25472, 17747,  ...,  7423, 17581, 20406]], device='cuda:0')\n",
      "### -17.697664260864258 -1388184.5 ###\n",
      "Batch 17/391: Loss: 10845.3301\n",
      "!!! torch.Size([128, 4097]) tensor([[49669, 40635, 45543,  ..., 14662, 47283,   594],\n",
      "        [12426, 20980, 23328,  ..., 20022, 14547, 14085],\n",
      "        [33192, 23599,  2935,  ..., 46605,  7226, 49314],\n",
      "        ...,\n",
      "        [37270, 16824,   510,  ..., 31222, 25689, 17660],\n",
      "        [25479, 24519, 46608,  ..., 20075, 20916, 33445],\n",
      "        [29148,  7549, 43903,  ..., 47804, 21518, 21886]], device='cuda:0')\n",
      "### -11.919478416442871 -1386399.25 ###\n",
      "Batch 18/391: Loss: 10831.3369\n",
      "!!! torch.Size([128, 4097]) tensor([[  855, 11883, 21162,  ..., 41090, 24384,   266],\n",
      "        [19588, 36044, 49092,  ..., 25242, 30175, 11077],\n",
      "        [31961, 23344, 32424,  ..., 22315, 11580, 40825],\n",
      "        ...,\n",
      "        [10862, 41536, 18792,  ..., 28115,  4616,  2553],\n",
      "        [28013, 25812, 21658,  ..., 15444, 26200,  4657],\n",
      "        [ 2184, 14015, 47699,  ..., 31049, 33391, 48526]], device='cuda:0')\n",
      "### -13.054744720458984 -1368382.25 ###\n",
      "Batch 19/391: Loss: 10690.5879\n",
      "!!! torch.Size([128, 4097]) tensor([[ 9634, 32203, 20964,  ..., 35105, 32204, 41127],\n",
      "        [ 6200,  5399,  7610,  ..., 46170, 20749, 29421],\n",
      "        [22083,   490, 27760,  ...,  6064, 42285, 24050],\n",
      "        ...,\n",
      "        [37853, 39430, 41214,  ..., 45591, 36121, 16831],\n",
      "        [22680, 41069, 38407,  ..., 10955, 47308,  3524],\n",
      "        [13426, 38088, 10049,  ...,  8209, 24852, 42259]], device='cuda:0')\n",
      "### -11.500429153442383 -1359234.5 ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3c35e-e2f1-4b43-a8a1-a527b753cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = kNN(0, net, lemniscate, trainloader, testloader, 200, nce_t, 1)\n",
    "print(f'Final Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a654f-4771-4332-b68c-0279e94047bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ffadd7-0b79-4d27-88aa-050d8e03b179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a113862-4f1f-40d5-9e9c-a1caf9289d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca536b5-3076-45d1-8c3b-2995599a90dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7085b-dad0-4625-a9e3-8ad29becc48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
