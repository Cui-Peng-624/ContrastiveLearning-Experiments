{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab27dc70-e66e-4473-b8ee-36aa7016b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "from AliasMethod import AliasMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3874ea70-17d3-4634-8acf-f30c237a68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0\n",
    "start_epoch = 0\n",
    "low_dim = 128\n",
    "nce_k = 1024 # defult 4096\n",
    "nce_t = 0.5 # 温度\n",
    "nce_m = 0.5 # SGD 动量参数\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422af2c4-f716-41b6-8f2b-83f13c2a85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Instance(torchvision.datasets.CIFAR10):\n",
    "    \"\"\"CIFAR10Instance Dataset.\"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            img, target = self.data[index], self.targets[index]\n",
    "        else:\n",
    "            img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        img = Image.fromarray(img) # 使用 Image.fromarray(img) 将从数据集中获取的 NumPy 数组（代表图像数据）转换为 PIL.Image.Image 对象，以便后续的图像处理操作\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None: # 如果 self.target_transform 不为 None，则对标签应用相应的转换。这可以用于标签的转换，例如将标签从一个格式转换到另一个格式\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7499215-14bf-420b-b0fb-281b8263e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n",
    "    # transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# d2l-zh/pytorch/MyExercises/data\n",
    "trainset = CIFAR10Instance(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = CIFAR10Instance(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "ndata = len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f47802-e8b6-4eb0-b571-82dfbd54641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch import nn\n",
    "# from .alias_multinomial import AliasMethod\n",
    "import math\n",
    "\n",
    "class NCEFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x, y, memory, idx, params): # features.shape=(batch_size, feature_size), indexes.shape=torch.Size([128]), memory bank, idx.shape(128,4097), params\n",
    "        K = int(params[0].item())  # 负样本的数量\n",
    "        T = params[1].item()  # 温度参数\n",
    "        Z = params[2].item()  # 归一化常数\n",
    "        momentum = params[3].item()  # 动量参数\n",
    "        batchSize = x.size(0)  # 当前批次的大小\n",
    "        outputSize = memory.size(0)  # memory bank 的大小\n",
    "        inputSize = memory.size(1)  # 输入特征的维度\n",
    "\n",
    "        # sample positives & negatives\n",
    "        idx.select(1,0).copy_(y.data) # 将正样本索引放入 idx 的第一列，这样idx的第一列就都是正样本，后面4096个都是负样本\n",
    "\n",
    "        # 采样相应的特征向量（正样本和负样本）\n",
    "        weight = torch.index_select(memory, 0, idx.view(-1)) # 从memory中提取出所有第0维（行），再按照idx.view(-1)的索引提取出指定的行 - (len(idx.view(-1)), inputSize)\n",
    "        # 感觉也不能说是weights吧，许多images的特征，用features似乎更合适一点\n",
    "        weight.resize_(batchSize, K+1, inputSize) # resize成跟idx一样的shape - (batchSize, K+1, inputSize) - (128, 4097, 128)\n",
    "\n",
    "        # inner product\n",
    "        out = torch.bmm(weight, x.data.resize_(batchSize, inputSize, 1)) # x.shape=(128,128), 所以这里的out就是(128, 4097, 1)，每个正样本和4097个样本（一正4096副）的内积\n",
    "        # 非参数softmax\n",
    "        # print(\"1\", out)\n",
    "        out.div_(T).exp_() # batchSize * self.K+1\n",
    "        # print(\"2\", out)\n",
    "        x.data.resize_(batchSize, inputSize)\n",
    "\n",
    "        if Z < 0: # Z 的设置: 如果 Z 小于 0，表示还没有初始化，因此在第一次计算时设置 Z 的值 - Z就是非参数softmax的分母\n",
    "            params[2] = out.mean() * outputSize # out.mean()生成单个数\n",
    "            Z = params[2].item() \n",
    "            print(\"normalization constant Z is set to {:.1f}\".format(Z))\n",
    "\n",
    "        out.div_(Z).resize_(batchSize, K+1) # 从(batchSize, K+1, 1) -> (batchSize, K+1)\n",
    "\n",
    "        # 保存用于反向传播的张量\n",
    "        self.save_for_backward(x, memory, y, weight, out, params)\n",
    "\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, gradOutput):\n",
    "        x, memory, y, weight, out, params = self.saved_tensors\n",
    "        K = int(params[0].item())\n",
    "        T = params[1].item()\n",
    "        Z = params[2].item()\n",
    "        momentum = params[3].item()\n",
    "        batchSize = gradOutput.size(0)\n",
    "        \n",
    "        # gradients d Pm / d linear = exp(linear) / Z????????? # 此时开始更新特征v，原文中equation2\n",
    "        gradOutput.data.mul_(out.data) # out.shape=(batchSize, K+1) # 应该是有一个近似，具体看平板\n",
    "        # add temperature # d exp(linear) / d (v_i)^T v = (1/T) * exp((v_i)^T v)\n",
    "        gradOutput.data.div_(T)\n",
    "\n",
    "        gradOutput.data.resize_(batchSize, 1, K+1)\n",
    "        \n",
    "        # gradient of linear \n",
    "        # print(gradOutput.shape, weight.shape) # torch.Size([128, 4097]) torch.Size([128, 4097, 128])\n",
    "        gradOutput = gradOutput.reshape(batchSize, 1, K+1) # 这一步源代码中没有\n",
    "        # d exp((v_i)^T v) / d v_i = exp((v_i)^T v) * v 吗？？？？？？？？？\n",
    "        # \\exp((v_i)^T v) \\) 对 \\( v_i \\) 的导数是 exp(v_i^T v) \\cdot v - GPT\n",
    "        # v就是weight - 果然有近似\n",
    "        gradInput = torch.bmm(gradOutput.data, weight) # (batchSize, 1, K+1) mm (batchSize, K+1, inputSize) -> (batchSize, 1, inputSize)\n",
    "        gradInput.resize_as_(x) # x.shape=(batch_size, feature_size=inputSize)\n",
    "\n",
    "        # update the non-parametric data - 更新memory bank中的特征v\n",
    "        # weight.shape =(batchSize, K+1, inputSize)\n",
    "        weight_pos = weight.select(1, 0).resize_as_(x) # 见下面的test - (batchSize, inputSize) 及所有批次的第一个样本的特征，及所有正样本的特征\n",
    "        weight_pos.mul_(momentum)\n",
    "        weight_pos.add_(torch.mul(x.data, 1-momentum)) # v_i' = \\text{momentum} \\cdot v_i + (1 - \\text{momentum}) \\cdot x\n",
    "        w_norm = weight_pos.pow(2).sum(1, keepdim=True).pow(0.5)\n",
    "        updated_weight = weight_pos.div(w_norm) # 将更新后的向量归一化，确保它的模为 1\n",
    "        memory.index_copy_(0, y, updated_weight)\n",
    "        \n",
    "        return gradInput, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0768d9b4-8767-471c-bd1e-faf342af5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCEAverage(nn.Module):\n",
    "\n",
    "    def __init__(self, inputSize, outputSize, K, T=0.07, momentum=0.5, Z=None):\n",
    "        super(NCEAverage, self).__init__()\n",
    "        self.nLem = outputSize\n",
    "        self.unigrams = torch.ones(self.nLem)\n",
    "        self.multinomial = AliasMethod(self.unigrams)\n",
    "        self.multinomial.cuda()\n",
    "        self.K = K\n",
    "\n",
    "        self.register_buffer('params',torch.tensor([K, T, -1, momentum]));\n",
    "        stdv = 1. / math.sqrt(inputSize/3)\n",
    "        self.register_buffer('memory', torch.rand(outputSize, inputSize).mul_(2*stdv).add_(-stdv))\n",
    " \n",
    "    def forward(self, x, y): # lemniscate(features, indexes); x - (batch_size, feature_size); y - (batch_size)\n",
    "        batchSize = x.size(0)\n",
    "        idx = self.multinomial.draw(batchSize * (self.K+1)).view(batchSize, -1)\n",
    "        # print(\"!!!\", idx.shape, idx) # torch.Size([128, 4097])\n",
    "        out = NCEFunction.apply(x, y, self.memory, idx, self.params)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbbb6aa4-4b01-49ef-a789-dbd780b9de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCECriterion(nn.Module):\n",
    "    def __init__(self, nLem):\n",
    "        super(NCECriterion, self).__init__()\n",
    "        self.nLem = nLem\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        batchSize = x.size(0)\n",
    "        K = x.size(1) - 1\n",
    "        Pnt = 1 / float(self.nLem)\n",
    "        Pns = 1 / float(self.nLem)\n",
    "\n",
    "        Pmt = x.select(1, 0)\n",
    "        Pmt_div = Pmt.add(K * Pnt + 1e-7)\n",
    "        lnPmt = torch.div(Pmt, Pmt_div)\n",
    "\n",
    "        Pon_div = x.narrow(1, 1, K).add(K * Pns + 1e-7)\n",
    "        # print(\"###########################\", Pon_div)\n",
    "        Pon = Pon_div.clone().fill_(K * Pns)\n",
    "        lnPon = torch.div(Pon, Pon_div)\n",
    "\n",
    "        lnPmt.log_()\n",
    "        lnPon.log_()\n",
    "\n",
    "        lnPmtsum = lnPmt.sum(0)\n",
    "        lnPonsum = lnPon.view(-1, 1).sum(0)\n",
    "\n",
    "        ######################################################\n",
    "        # print(\"###\", lnPmtsum.item(), \"###\", lnPonsum.item(), \"###\",)\n",
    "        loss = - (lnPmtsum + lnPonsum) / batchSize\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20b72e4f-89d0-4bbe-90a5-32e9ae226589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model..')\n",
    "net = torchvision.models.resnet18(num_classes=low_dim)  # Using ResNet18 with the low_dim output\n",
    "lemniscate = NCEAverage(low_dim, ndata, nce_k, nce_t, nce_m)\n",
    "\n",
    "# if device == 'cuda':\n",
    "#     net = nn.DataParallel(net).to(device)\n",
    "#     cudnn.benchmark = True\n",
    "net.to(device)\n",
    "lemniscate.to(device)\n",
    "\n",
    "criterion = NCECriterion(ndata).to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee81e3ea-a0ce-4aa5-9a46-842717967df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 80 epochs\"\"\"\n",
    "    lr = learning_rate\n",
    "    if epoch >= 80:\n",
    "        lr *= 0.1 ** ((epoch - 80) // 40)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9115ad4-229b-4141-add7-2b4ebd2981e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_load_checkpoint import save_checkpoint\n",
    "\n",
    "def train(epoch, model_path, optimizer_path, best_loss=None):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    net.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    for batch_idx, (inputs, targets, indexes) in enumerate(trainloader):\n",
    "        inputs, targets, indexes = inputs.to(device), targets.to(device), indexes.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        features = net(inputs)\n",
    "        outputs = lemniscate(features, indexes)\n",
    "        loss = criterion(outputs, indexes)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 每 100 个 batch 打印一次损失\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(trainloader)}: Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # 计算当前 epoch 的平均损失\n",
    "    avg_loss = train_loss / len(trainloader)\n",
    "    \n",
    "    # 如果当前损失低于最小损失，则保存模型\n",
    "    if best_loss is None or avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        save_checkpoint(net, optimizer, epoch, model_path, optimizer_path)\n",
    "        print(f'New best loss: {best_loss:.4f} - Model saved.')\n",
    "    else:\n",
    "        print(f'Epoch {epoch} completed with loss: {avg_loss:.4f}, no improvement from best loss: {best_loss:.4f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "933de7ac-fcaf-46ca-b998-53ab9f8353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    acc = kNN(epoch, net, lemniscate, trainloader, testloader, 200, nce_t, 0)\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'lemniscate': lemniscate,\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "\n",
    "    print(f'Best Accuracy: {best_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "036a843e-0cec-4c49-8188-f8b426285f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "normalization constant Z is set to 296483.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\envs\\DL_learning\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/782: Loss: 9.5734\n",
      "Batch 100/782: Loss: 9.1923\n",
      "Batch 200/782: Loss: 8.7931\n",
      "Batch 300/782: Loss: 9.0037\n",
      "Batch 400/782: Loss: 9.0685\n",
      "Batch 500/782: Loss: 8.8031\n",
      "Batch 600/782: Loss: 9.0971\n",
      "Batch 700/782: Loss: 8.8185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\envs\\DL_learning\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizer states saved to checkpoints/cifar10/cifar10.pth and checkpoints/cifar10/cifar10.pth.\n",
      "New best loss: 9.0421 - Model saved.\n",
      "\n",
      "Epoch: 1\n",
      "Batch 0/782: Loss: 8.7285\n",
      "Batch 100/782: Loss: 8.1204\n",
      "Batch 200/782: Loss: 8.2326\n",
      "Batch 300/782: Loss: 7.8456\n",
      "Batch 400/782: Loss: 8.3071\n",
      "Batch 500/782: Loss: 7.9908\n",
      "Batch 600/782: Loss: 8.0225\n",
      "Batch 700/782: Loss: 8.1245\n",
      "Model and optimizer states saved to checkpoints/cifar10/cifar10.pth and checkpoints/cifar10/cifar10.pth.\n",
      "New best loss: 8.0599 - Model saved.\n",
      "\n",
      "Epoch: 2\n",
      "Batch 0/782: Loss: 6.6091\n",
      "Batch 100/782: Loss: 5.7945\n",
      "Batch 200/782: Loss: 6.2444\n",
      "Batch 300/782: Loss: 6.6357\n",
      "Batch 400/782: Loss: 6.4408\n",
      "Batch 500/782: Loss: 5.9939\n",
      "Batch 600/782: Loss: 6.5664\n",
      "Batch 700/782: Loss: 6.6244\n",
      "Model and optimizer states saved to checkpoints/cifar10/cifar10.pth and checkpoints/cifar10/cifar10.pth.\n",
      "New best loss: 6.1298 - Model saved.\n",
      "\n",
      "Epoch: 3\n",
      "Batch 0/782: Loss: 5.0156\n",
      "Batch 100/782: Loss: 5.8160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = None\n",
    "model_path = 'checkpoints/cifar10/cifar10.pth'\n",
    "optimizer_path = 'checkpoints/cifar10/cifar10.pth'\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "    train(epoch, model_path, optimizer_path, best_loss)\n",
    "    # test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02d1c7-bd97-406d-97b4-cc0c93db7cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45d777-2bd1-4a4a-be44-b4efa194f610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463c71e-c312-4309-b312-b9ccc3d14e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0474061f-55f5-4fa2-adfd-248d055c9eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845c350-1bf4-401e-9350-cd696aab5ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d023223-3c6c-4612-85c2-5fbd0fcef460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
