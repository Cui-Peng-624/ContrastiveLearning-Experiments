{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804c5778-459c-4a8b-9c6c-df2c99f36a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import math\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8ccb31-90e5-46af-b58f-609c7dbc1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 512\n",
    "low_dim = 128\n",
    "lr = 0.03\n",
    "batch_m = 1\n",
    "batch_t = 100 # 1会爆炸，更不用说更小的了，10也会爆炸\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed5cb8e-f6ff-4bff-bc73-c352340fdd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Instance(datasets.CIFAR10):\n",
    "    \"\"\"CIFAR10Instance Dataset.\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img)\n",
    "            if self.train:\n",
    "                img2 = self.transform(img)\n",
    "\n",
    "        if self.train:\n",
    "            return img1, img2, target, index\n",
    "        else:\n",
    "            return img1, target, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfa943c-e5a7-46e5-ae4e-eb78bc8b17a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20703\\d2l-zh\\pytorch\\MyExercises\\对比学习\\1. Unsupervised Feature Learning via Non-parameteric Instance Discrimination\\data\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 获取当前脚本的绝对路径\n",
    "current_dir = os.path.dirname(os.path.abspath(\"Untitled.ipynb\"))\n",
    "# 构建 a/b/data 文件夹的路径\n",
    "data_dir = os.path.abspath(os.path.join(current_dir, '..', '1. Unsupervised Feature Learning via Non-parameteric Instance Discrimination', 'data'))\n",
    "print(data_dir)\n",
    "\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=32, scale=(0.2,1.)),\n",
    "    transforms.ColorJitter(0.4, 0.4, 0.4, 0),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 使用构建的路径来访问数据集\n",
    "trainset = CIFAR10Instance(root=data_dir, train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last =True)\n",
    "\n",
    "testset = CIFAR10Instance(root=data_dir, train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, drop_last =True)\n",
    "\n",
    "ndata = len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9669ab56-3a7f-463f-9647-2d50809d2ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3, 32, 32]) torch.Size([512, 3, 32, 32]) torch.Size([512]) torch.Size([512])\n",
      "tensor([9, 8, 1, 1, 1, 0, 0, 9, 1, 6, 0, 9, 7, 0, 8, 0, 6, 9, 4, 0, 0, 8, 5, 8,\n",
      "        2, 4, 3, 6, 4, 1, 8, 1, 1, 8, 8, 4, 6, 1, 1, 5, 0, 1, 9, 1, 1, 3, 7, 6,\n",
      "        8, 2, 0, 1, 9, 5, 9, 0, 2, 1, 6, 0, 3, 9, 9, 2, 6, 4, 6, 9, 0, 7, 7, 5,\n",
      "        3, 7, 2, 2, 7, 2, 8, 6, 3, 9, 3, 3, 7, 5, 6, 4, 0, 1, 0, 3, 1, 3, 6, 4,\n",
      "        6, 2, 2, 2, 7, 1, 3, 2, 9, 4, 5, 5, 5, 0, 7, 4, 2, 6, 4, 6, 4, 0, 6, 3,\n",
      "        4, 7, 0, 6, 9, 7, 7, 8, 5, 3, 9, 2, 9, 5, 1, 5, 5, 2, 8, 2, 1, 2, 0, 1,\n",
      "        2, 9, 1, 9, 3, 5, 6, 9, 2, 2, 2, 1, 0, 8, 2, 0, 5, 6, 0, 5, 8, 9, 5, 7,\n",
      "        7, 7, 8, 3, 9, 7, 1, 5, 9, 5, 2, 5, 7, 4, 1, 1, 4, 2, 8, 3, 8, 8, 0, 4,\n",
      "        8, 1, 7, 2, 0, 1, 8, 1, 2, 7, 3, 5, 2, 1, 8, 1, 5, 1, 1, 6, 1, 7, 3, 2,\n",
      "        7, 4, 4, 4, 0, 7, 2, 6, 0, 5, 5, 4, 0, 4, 5, 7, 6, 2, 3, 9, 7, 9, 7, 5,\n",
      "        9, 8, 9, 7, 2, 2, 5, 7, 7, 7, 0, 7, 8, 7, 5, 1, 7, 5, 5, 4, 3, 7, 9, 9,\n",
      "        9, 6, 6, 3, 0, 8, 4, 3, 9, 8, 3, 1, 3, 3, 3, 3, 9, 3, 9, 0, 0, 1, 6, 6,\n",
      "        5, 1, 1, 3, 5, 9, 0, 9, 1, 8, 0, 7, 6, 6, 9, 1, 9, 6, 4, 4, 0, 7, 2, 4,\n",
      "        1, 2, 0, 7, 2, 3, 4, 8, 0, 4, 2, 9, 8, 3, 4, 4, 2, 9, 7, 7, 4, 0, 2, 4,\n",
      "        3, 4, 6, 0, 2, 3, 8, 8, 6, 6, 4, 4, 6, 9, 2, 5, 2, 9, 0, 3, 2, 1, 3, 3,\n",
      "        2, 7, 8, 7, 7, 2, 2, 0, 0, 2, 7, 7, 5, 0, 3, 8, 2, 3, 0, 1, 3, 4, 9, 2,\n",
      "        2, 7, 6, 9, 7, 7, 1, 8, 5, 2, 9, 8, 8, 2, 0, 0, 5, 1, 6, 9, 7, 4, 1, 1,\n",
      "        2, 3, 8, 6, 6, 2, 4, 8, 2, 7, 9, 6, 1, 6, 5, 7, 9, 1, 7, 9, 2, 3, 3, 7,\n",
      "        4, 5, 6, 2, 5, 9, 2, 9, 3, 3, 9, 0, 2, 9, 4, 7, 0, 7, 2, 0, 4, 6, 7, 7,\n",
      "        0, 0, 7, 2, 4, 5, 2, 6, 0, 5, 2, 5, 2, 7, 9, 7, 1, 0, 0, 5, 3, 7, 2, 4,\n",
      "        8, 4, 1, 6, 5, 6, 2, 7, 5, 2, 9, 4, 8, 2, 8, 7, 2, 7, 0, 3, 9, 3, 3, 2,\n",
      "        2, 4, 0, 6, 2, 8, 6, 9]) tensor([27997, 30087, 41666, 42539, 43235, 35202, 21881, 27811, 21137, 34804,\n",
      "        17963, 12186, 43706, 16100, 29617,  7573, 46388,  4784, 42863, 21404,\n",
      "         3334, 10228, 34880, 16991, 13492,  7078, 15799, 21872, 20374, 23156,\n",
      "        13241, 13444, 32295, 17335, 17416,  9349, 34311, 30244, 27330, 47620,\n",
      "        43754, 43847, 33568, 44549,  1547, 21122, 24449, 26383,  2670, 35319,\n",
      "        30652, 27354, 11275, 10971, 10793, 20722, 28224, 49022, 22885, 38205,\n",
      "        20345, 17869, 31010, 49099, 46263, 30677, 25612, 26970, 37246, 38604,\n",
      "        36959, 15499, 46399, 31082, 42168,  4034, 38025, 29087,  7118, 44602,\n",
      "        47737, 48196, 34710, 39665, 10037, 25390, 32707, 47622, 45827,  8977,\n",
      "        16148, 19920, 11134, 13907, 18936, 46648, 48765, 11710, 12058, 48522,\n",
      "        12476,  9189,  3003, 46216, 22475,   764, 28756, 30506, 49514, 49869,\n",
      "        19159, 15643, 48598, 22610, 33080, 18903, 17033,   757, 41796, 43726,\n",
      "        23779, 37810, 25160,  1393,   791,  2614, 41956, 42807, 39147, 44663,\n",
      "        35297, 11630, 34085, 14960, 13526, 16524, 47173, 13341, 23965, 17089,\n",
      "        28761, 15584, 22304, 34069,  3331, 24458, 45968,  5772, 17646, 32048,\n",
      "          863, 17875,  9712, 42043, 29079, 19947, 39236, 41375, 32711, 25288,\n",
      "        33142,  2684,  2512, 42494, 43699, 24173,  6958, 23928, 24940, 13888,\n",
      "        10088, 30060, 19805, 42078,   942, 23007, 46775, 10324, 40727, 39228,\n",
      "        15055, 31998, 49663, 26899, 23161, 31419,  2881,  6902, 42135, 41543,\n",
      "        31004, 31084, 10721,  6869, 24974, 35486, 12740, 20911, 46926, 11645,\n",
      "        29541, 32428, 17644, 12281, 23843, 48441, 48602, 44269, 34877, 49849,\n",
      "        28005,  8033, 22930, 36597, 26642, 48989, 13092, 30289, 33744, 22183,\n",
      "        40442,  6680, 17826,  1420, 35883, 43107, 29521, 33610,  5324, 26329,\n",
      "         8511,  7830, 36906, 12471, 39374,  9573, 37200, 21700,  6734, 10230,\n",
      "        25708, 14876, 16267,  5436, 14029,   138, 32336, 21660, 43894, 17463,\n",
      "        44731, 44935, 16206, 11051,  1580, 47362,  7314,  2246, 42317, 28470,\n",
      "        48183, 42546, 26839, 15330, 41228, 48463,   210, 42736,  6904, 42182,\n",
      "        19180, 20569, 16699,  8022,  3795, 40602,  9794, 21640, 41461, 13330,\n",
      "         5002, 38147,  3097, 21732, 10394, 12127, 21620, 37835, 44832, 12856,\n",
      "        44281, 11236,  9665,  4256, 10266, 30161, 30613, 30483,  5814, 14356,\n",
      "        42334,   920, 35504, 12814, 26385,  4785,  2385, 30256, 39288, 35589,\n",
      "        15828, 28576,   833, 38573, 26985,  5842, 39478, 38521, 11045, 47758,\n",
      "        24476, 14263, 11443, 11797,  8163, 41815, 39656,  8049, 24798, 45612,\n",
      "        29370, 12572,  6303, 13043, 15705, 20730, 48131, 27847, 36749, 36395,\n",
      "        22307, 16341, 10191, 38339, 17301,  6893,  9568, 40397, 45350,  2061,\n",
      "        48472, 26867,  3164, 35702, 33229, 45319,  6946, 15308, 13602, 48798,\n",
      "        47932, 20166, 23946, 12464, 45851, 31705, 22803, 39104, 31756, 25415,\n",
      "        20062, 24794, 42530,  8249, 14313, 11667, 29389,  2648, 15548, 24385,\n",
      "        36709, 16908,     2, 16249, 25446, 34151, 34602, 47699,  3627, 30409,\n",
      "        35878, 37420, 41587, 37232, 31067, 27339, 42280, 26992, 19173, 39196,\n",
      "        23874,  2339,  2226, 38926, 29778,  9887,  6589, 29932, 35243, 41269,\n",
      "         7376,   249, 23087, 21115,  6681, 35562,  4198, 13353, 28229, 42358,\n",
      "        43932,  8816, 11094, 26356, 42981, 11716, 41985,  2332, 31687, 22916,\n",
      "        30541, 18537, 17437, 16873, 26240,  1207,  3894, 22466, 49756, 15280,\n",
      "        25943, 18769, 30998, 43483,   885,   438, 41699, 49737, 21564, 18401,\n",
      "         4931,  4311, 27180, 34288, 28764, 36499, 47726, 36038,  9186, 32456,\n",
      "        15990, 39551, 47252, 27708, 25083, 17236,  6362, 42505, 11985, 38128,\n",
      "        38789, 26270, 18332, 40197, 38796, 16009,  1568, 21995,  5762, 34589,\n",
      "        47445, 36292, 22490,  1628, 12649, 20734, 16207,  6892,  1911, 34597,\n",
      "        45048, 37839,  4222,  2975,  8715, 38284, 34968, 28398,  2264, 45754,\n",
      "        21592, 36961, 32939, 40786, 49987, 48008, 40796,  4434, 41084, 19309,\n",
      "         8557, 49087])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# from ImageTensor import tensor_to_image\n",
    "\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 定义可视化函数\n",
    "# def visualize_tensor(tensor, indices, title=\"\"):\n",
    "#     fig, axes = plt.subplots(1, len(indices), figsize=(9, 3))\n",
    "#     if len(indices) == 1:\n",
    "#         axes = [axes]  # 将单个AxesSubplot对象包装成一个列表\n",
    "#     for ax, idx in zip(axes, indices):\n",
    "#         image = tensor[idx, 0].detach().cpu().numpy()\n",
    "#         ax.imshow(image, cmap='gray')\n",
    "#         ax.set_title(f\"Image {idx+1}\")\n",
    "#         ax.axis('off')\n",
    "#     fig.suptitle(title)\n",
    "#     plt.show()\n",
    "\n",
    "# 在训练过程中调用\n",
    "for batch_idx, (inputs1, inputs2, target, indexes) in enumerate(trainloader):\n",
    "    print(inputs1.shape, inputs2.shape, target.shape, indexes.shape)\n",
    "    print(target, indexes)\n",
    "    # visualize_tensor(inputs, [1, 2, 3])\n",
    "    # 将 PyTorch Tensor 转换为图像\n",
    "    # inputs1_image = tensor_to_image(inputs1[1].permute(1, 2, 0))\n",
    "    # inputs2_image = tensor_to_image(inputs2[1].permute(1, 2, 0))\n",
    "    # inputs2_image.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a626623-41a1-4a3a-abc8-82e51494c909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BatchCriterion()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('==> Building model..')\n",
    "net = torchvision.models.resnet18(num_classes=low_dim)  # Using ResNet18 with the low_dim output\n",
    "\n",
    "from BatchAverage import BatchCriterion\n",
    "\n",
    "\"\"\"\n",
    "parser.add_argument('--batch-t', default=0.1, type=float,\n",
    "                    metavar='T', help='temperature parameter for softmax')\n",
    "parser.add_argument('--batch-m', default=1, type=float,\n",
    "                    metavar='N', help='m for negative sum')\n",
    "\n",
    "\"def __init__(self, negM, T, batchSize):\"\n",
    "\n",
    "self.negM = negM:\n",
    "这里 negM 是一个参数，代表负样本的加权系数。它用于控制负样本的权重，在损失计算中会用到。\n",
    "\n",
    "self.T = T:\n",
    "T 是温度参数，用于缩放内积值，使得 softmax 函数更加平滑。较小的 T 会使得模型对小的差异更加敏感，较大的 T 会使得模型的输出更加均匀。\n",
    "\"\"\"\n",
    "# define loss function: inner product loss within each mini-batch\n",
    "criterion = BatchCriterion(batch_m, batch_t, batch_size)\n",
    "\n",
    "net.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a16178f-3246-4f8c-a62a-9bfc1f5f53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7684a917-4a8a-4d90-b999-f997c304aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed at 120, 160 and 200\"\"\"\n",
    "    lr = 0.03\n",
    "    if epoch >= 120 and epoch < 160:\n",
    "        lr = args.lr * 0.1\n",
    "    elif epoch >= 160 and epoch <200:\n",
    "        lr = args.lr * 0.05\n",
    "    elif epoch >= 200:\n",
    "        lr = args.lr * 0.01\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr   \n",
    "    # writer.add_scalar('lr',  lr, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c043af-907d-4024-89f8-210a3b3c9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\" \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "                   \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0 \n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6222f4e4-9997-49b1-9010-4a97479c0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train_loss = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    net.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (inputs1, inputs2, _, indexes) in enumerate(trainloader):#\n",
    "        # inputs1.shape, inputs2.shape, target.shape, indexes.shape\n",
    "        # torch.Size([64, 3, 32, 32]) torch.Size([64, 3, 32, 32]) torch.Size([64]) torch.Size([64])\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        inputs1, inputs2, indexes = inputs1.to(device), inputs2.to(device), indexes.to(device)\n",
    "        \n",
    "        inputs = torch.cat((inputs1,inputs2), 0) # (128, 3, 32, 32)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        features = net(inputs) # features.shape = (128, 128)\n",
    "        # print(\"###\", features.shape, \"###\", indexes.shape, \"###\") # ### torch.Size([128, 128]) ### torch.Size([64]) ### batch_size设置的是64\n",
    "        loss = criterion(features, indexes) # features 是64原数据+64增强数据的特征，indexes是64原数据对应的index（不是target，label）\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.update(loss.item(), inputs.size(0))         \n",
    "        \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if batch_idx%1 ==0:\n",
    "            print('Epoch: [{}][{}/{}] '\n",
    "                  'Time: {batch_time.val:.3f} ({batch_time.avg:.3f}) '\n",
    "                  'Data: {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Loss: {train_loss.val:.4f} ({train_loss.avg:.4f})'.format(\n",
    "                  epoch, batch_idx, len(trainloader), batch_time=batch_time, data_time=data_time, train_loss=train_loss))\n",
    "    # add log\n",
    "    # writer.add_scalar('loss',  train_loss.avg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1b995d-3c1c-4f68-88ac-c8cc1dd4fc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\envs\\DL_learning\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "D:\\Miniconda\\envs\\DL_learning\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/97] Time: 3.441 (3.441) Data: 1.710 (1.710) Loss: 7.9117 (7.9117)\n",
      "Epoch: [0][1/97] Time: 2.315 (2.878) Data: 1.383 (1.546) Loss: 7.9088 (7.9102)\n",
      "Epoch: [0][2/97] Time: 2.181 (2.646) Data: 1.097 (1.396) Loss: 7.9158 (7.9121)\n",
      "Epoch: [0][3/97] Time: 2.430 (2.592) Data: 1.501 (1.423) Loss: 7.9042 (7.9101)\n",
      "Epoch: [0][4/97] Time: 1.900 (2.454) Data: 0.969 (1.332) Loss: 7.9079 (7.9097)\n",
      "Epoch: [0][5/97] Time: 1.750 (2.336) Data: 0.824 (1.247) Loss: 7.9094 (7.9096)\n",
      "Epoch: [0][6/97] Time: 1.988 (2.287) Data: 0.818 (1.186) Loss: 7.8974 (7.9079)\n",
      "Epoch: [0][7/97] Time: 2.044 (2.256) Data: 1.112 (1.177) Loss: 7.8886 (7.9055)\n",
      "Epoch: [0][8/97] Time: 2.149 (2.244) Data: 1.088 (1.167) Loss: 7.8855 (7.9033)\n",
      "Epoch: [0][9/97] Time: 2.049 (2.225) Data: 1.109 (1.161) Loss: 7.8769 (7.9006)\n",
      "Epoch: [0][10/97] Time: 2.010 (2.205) Data: 0.820 (1.130) Loss: 7.8710 (7.8979)\n",
      "Epoch: [0][11/97] Time: 2.009 (2.189) Data: 0.810 (1.103) Loss: 7.8830 (7.8967)\n",
      "Epoch: [0][12/97] Time: 1.729 (2.154) Data: 0.794 (1.080) Loss: 7.8442 (7.8926)\n",
      "Epoch: [0][13/97] Time: 1.971 (2.140) Data: 1.018 (1.075) Loss: 7.8536 (7.8898)\n",
      "Epoch: [0][14/97] Time: 2.271 (2.149) Data: 1.194 (1.083) Loss: 7.8437 (7.8868)\n",
      "Epoch: [0][15/97] Time: 2.159 (2.150) Data: 1.231 (1.092) Loss: 7.8079 (7.8818)\n",
      "Epoch: [0][16/97] Time: 2.450 (2.167) Data: 1.370 (1.109) Loss: 7.7992 (7.8770)\n",
      "Epoch: [0][17/97] Time: 2.216 (2.170) Data: 1.280 (1.118) Loss: 7.8047 (7.8730)\n",
      "Epoch: [0][18/97] Time: 2.184 (2.171) Data: 1.251 (1.125) Loss: 7.8130 (7.8698)\n",
      "Epoch: [0][19/97] Time: 1.972 (2.161) Data: 0.920 (1.115) Loss: 7.7507 (7.8639)\n",
      "Epoch: [0][20/97] Time: 2.118 (2.159) Data: 1.068 (1.113) Loss: 7.7446 (7.8582)\n",
      "Epoch: [0][21/97] Time: 2.109 (2.157) Data: 1.050 (1.110) Loss: 7.6908 (7.8506)\n",
      "Epoch: [0][22/97] Time: 2.323 (2.164) Data: 1.280 (1.117) Loss: 7.6808 (7.8432)\n",
      "Epoch: [0][23/97] Time: 3.460 (2.218) Data: 2.348 (1.169) Loss: 7.6876 (7.8367)\n",
      "Epoch: [0][24/97] Time: 2.738 (2.239) Data: 1.665 (1.188) Loss: 7.6644 (7.8298)\n",
      "Epoch: [0][25/97] Time: 2.600 (2.253) Data: 1.522 (1.201) Loss: 7.6271 (7.8220)\n",
      "Epoch: [0][26/97] Time: 2.172 (2.250) Data: 1.110 (1.198) Loss: 7.6419 (7.8153)\n",
      "Epoch: [0][27/97] Time: 1.988 (2.240) Data: 0.938 (1.189) Loss: 7.6293 (7.8087)\n",
      "Epoch: [0][28/97] Time: 2.999 (2.266) Data: 1.860 (1.212) Loss: 7.5656 (7.8003)\n",
      "Epoch: [0][29/97] Time: 3.371 (2.303) Data: 2.177 (1.244) Loss: 7.5881 (7.7932)\n",
      "Epoch: [0][30/97] Time: 3.242 (2.334) Data: 2.103 (1.272) Loss: 7.6047 (7.7872)\n",
      "Epoch: [0][31/97] Time: 4.191 (2.392) Data: 3.002 (1.326) Loss: 7.5438 (7.7796)\n",
      "Epoch: [0][32/97] Time: 5.477 (2.485) Data: 4.331 (1.417) Loss: 7.5168 (7.7716)\n",
      "Epoch: [0][33/97] Time: 5.400 (2.571) Data: 4.165 (1.498) Loss: 7.4585 (7.7624)\n",
      "Epoch: [0][34/97] Time: 6.035 (2.670) Data: 4.849 (1.593) Loss: 7.4931 (7.7547)\n",
      "Epoch: [0][35/97] Time: 6.235 (2.769) Data: 4.980 (1.687) Loss: 7.4670 (7.7467)\n",
      "Epoch: [0][36/97] Time: 4.761 (2.823) Data: 3.593 (1.739) Loss: 7.4461 (7.7386)\n",
      "Epoch: [0][37/97] Time: 4.059 (2.855) Data: 2.972 (1.771) Loss: 7.4297 (7.7304)\n",
      "Epoch: [0][38/97] Time: 3.193 (2.864) Data: 2.048 (1.778) Loss: 7.4536 (7.7233)\n",
      "Epoch: [0][39/97] Time: 3.245 (2.873) Data: 2.016 (1.784) Loss: 7.4154 (7.7156)\n",
      "Epoch: [0][40/97] Time: 3.030 (2.877) Data: 1.923 (1.788) Loss: 7.3524 (7.7068)\n",
      "Epoch: [0][41/97] Time: 2.344 (2.864) Data: 1.295 (1.776) Loss: 7.4667 (7.7011)\n",
      "Epoch: [0][42/97] Time: 2.081 (2.846) Data: 1.149 (1.761) Loss: 7.3504 (7.6929)\n",
      "Epoch: [0][43/97] Time: 1.929 (2.825) Data: 0.785 (1.739) Loss: 7.3752 (7.6857)\n",
      "Epoch: [0][44/97] Time: 1.643 (2.799) Data: 0.711 (1.716) Loss: 7.3203 (7.6776)\n",
      "Epoch: [0][45/97] Time: 1.678 (2.775) Data: 0.749 (1.695) Loss: 7.2797 (7.6689)\n",
      "Epoch: [0][46/97] Time: 1.934 (2.757) Data: 0.926 (1.679) Loss: 7.3347 (7.6618)\n",
      "Epoch: [0][47/97] Time: 1.880 (2.739) Data: 0.947 (1.664) Loss: 7.3332 (7.6550)\n",
      "Epoch: [0][48/97] Time: 2.103 (2.726) Data: 1.012 (1.650) Loss: 7.2924 (7.6476)\n",
      "Epoch: [0][49/97] Time: 1.750 (2.706) Data: 0.816 (1.634) Loss: 7.3572 (7.6418)\n",
      "Epoch: [0][50/97] Time: 1.772 (2.688) Data: 0.721 (1.616) Loss: 7.2506 (7.6341)\n",
      "Epoch: [0][51/97] Time: 1.755 (2.670) Data: 0.721 (1.599) Loss: 7.2274 (7.6263)\n",
      "Epoch: [0][52/97] Time: 1.667 (2.651) Data: 0.733 (1.582) Loss: 7.2351 (7.6189)\n",
      "Epoch: [0][53/97] Time: 1.756 (2.634) Data: 0.722 (1.566) Loss: 7.1851 (7.6109)\n",
      "Epoch: [0][54/97] Time: 1.906 (2.621) Data: 0.840 (1.553) Loss: 7.2275 (7.6039)\n",
      "Epoch: [0][55/97] Time: 1.964 (2.609) Data: 1.032 (1.544) Loss: 7.2383 (7.5974)\n",
      "Epoch: [0][56/97] Time: 2.174 (2.602) Data: 1.141 (1.537) Loss: 7.2228 (7.5908)\n",
      "Epoch: [0][57/97] Time: 2.117 (2.593) Data: 1.185 (1.531) Loss: 7.1878 (7.5838)\n",
      "Epoch: [0][58/97] Time: 1.824 (2.580) Data: 0.888 (1.520) Loss: 7.2269 (7.5778)\n",
      "Epoch: [0][59/97] Time: 1.707 (2.566) Data: 0.774 (1.507) Loss: 7.1587 (7.5708)\n",
      "Epoch: [0][60/97] Time: 1.818 (2.554) Data: 0.888 (1.497) Loss: 7.1659 (7.5642)\n",
      "Epoch: [0][61/97] Time: 2.015 (2.545) Data: 0.833 (1.487) Loss: 7.1892 (7.5581)\n",
      "Epoch: [0][62/97] Time: 2.001 (2.536) Data: 0.795 (1.476) Loss: 7.2145 (7.5527)\n",
      "Epoch: [0][63/97] Time: 2.087 (2.529) Data: 1.153 (1.471) Loss: 7.1279 (7.5460)\n",
      "Epoch: [0][64/97] Time: 2.422 (2.528) Data: 1.355 (1.469) Loss: 7.1066 (7.5393)\n",
      "Epoch: [0][65/97] Time: 2.441 (2.526) Data: 1.508 (1.469) Loss: 7.0660 (7.5321)\n",
      "Epoch: [0][66/97] Time: 2.550 (2.527) Data: 1.618 (1.472) Loss: 7.0149 (7.5244)\n",
      "Epoch: [0][67/97] Time: 2.162 (2.521) Data: 0.991 (1.465) Loss: 7.1117 (7.5183)\n",
      "Epoch: [0][68/97] Time: 1.875 (2.512) Data: 0.944 (1.457) Loss: 7.1009 (7.5123)\n",
      "Epoch: [0][69/97] Time: 2.108 (2.506) Data: 1.065 (1.451) Loss: 7.0412 (7.5055)\n",
      "Epoch: [0][70/97] Time: 2.729 (2.509) Data: 1.665 (1.454) Loss: 7.0207 (7.4987)\n",
      "Epoch: [0][71/97] Time: 2.622 (2.511) Data: 1.687 (1.458) Loss: 7.0238 (7.4921)\n",
      "Epoch: [0][72/97] Time: 2.519 (2.511) Data: 1.589 (1.459) Loss: 7.0507 (7.4861)\n",
      "Epoch: [0][73/97] Time: 2.868 (2.516) Data: 1.747 (1.463) Loss: 7.0475 (7.4801)\n",
      "Epoch: [0][74/97] Time: 2.369 (2.514) Data: 1.353 (1.462) Loss: 7.0428 (7.4743)\n",
      "Epoch: [0][75/97] Time: 4.009 (2.533) Data: 2.835 (1.480) Loss: 7.0130 (7.4682)\n",
      "Epoch: [0][76/97] Time: 4.039 (2.553) Data: 2.916 (1.499) Loss: 7.0199 (7.4624)\n",
      "Epoch: [0][77/97] Time: 5.066 (2.585) Data: 3.985 (1.530) Loss: 6.9810 (7.4562)\n",
      "Epoch: [0][78/97] Time: 7.802 (2.651) Data: 6.574 (1.594) Loss: 6.9634 (7.4500)\n",
      "Epoch: [0][79/97] Time: 8.029 (2.718) Data: 6.882 (1.660) Loss: 6.9994 (7.4444)\n",
      "Epoch: [0][80/97] Time: 7.014 (2.772) Data: 5.826 (1.712) Loss: 6.8599 (7.4372)\n",
      "Epoch: [0][81/97] Time: 5.436 (2.804) Data: 4.366 (1.744) Loss: 6.9646 (7.4314)\n",
      "Epoch: [0][82/97] Time: 3.574 (2.813) Data: 2.430 (1.752) Loss: 6.9440 (7.4255)\n",
      "Epoch: [0][83/97] Time: 3.053 (2.816) Data: 1.941 (1.755) Loss: 6.9399 (7.4197)\n",
      "Epoch: [0][84/97] Time: 3.226 (2.821) Data: 2.155 (1.759) Loss: 6.8845 (7.4134)\n",
      "Epoch: [0][85/97] Time: 2.705 (2.820) Data: 1.623 (1.758) Loss: 6.8943 (7.4074)\n",
      "Epoch: [0][86/97] Time: 2.126 (2.812) Data: 1.198 (1.751) Loss: 6.8928 (7.4015)\n",
      "Epoch: [0][87/97] Time: 2.308 (2.806) Data: 1.154 (1.745) Loss: 6.9010 (7.3958)\n",
      "Epoch: [0][88/97] Time: 1.896 (2.796) Data: 0.968 (1.736) Loss: 6.9033 (7.3903)\n",
      "Epoch: [0][89/97] Time: 2.134 (2.788) Data: 0.980 (1.727) Loss: 6.8984 (7.3848)\n",
      "Epoch: [0][90/97] Time: 1.966 (2.779) Data: 0.888 (1.718) Loss: 6.8894 (7.3794)\n",
      "Epoch: [0][91/97] Time: 2.101 (2.772) Data: 1.169 (1.712) Loss: 6.9096 (7.3743)\n",
      "Epoch: [0][92/97] Time: 2.049 (2.764) Data: 1.000 (1.705) Loss: 6.8562 (7.3687)\n",
      "Epoch: [0][93/97] Time: 2.153 (2.758) Data: 1.111 (1.698) Loss: 6.9256 (7.3640)\n",
      "Epoch: [0][94/97] Time: 2.077 (2.750) Data: 1.152 (1.693) Loss: 6.7703 (7.3577)\n",
      "Epoch: [0][95/97] Time: 2.110 (2.744) Data: 0.951 (1.685) Loss: 6.7678 (7.3516)\n",
      "Epoch: [0][96/97] Time: 1.931 (2.735) Data: 0.993 (1.678) Loss: 6.8849 (7.3468)\n",
      "\n",
      "Epoch: 1\n",
      "Epoch: [1][0/97] Time: 1.871 (1.871) Data: 0.789 (0.789) Loss: 6.7336 (6.7336)\n",
      "Epoch: [1][1/97] Time: 1.775 (1.823) Data: 0.707 (0.748) Loss: 6.8324 (6.7830)\n",
      "Epoch: [1][2/97] Time: 1.642 (1.763) Data: 0.702 (0.733) Loss: 6.8242 (6.7967)\n",
      "Epoch: [1][3/97] Time: 1.893 (1.795) Data: 0.958 (0.789) Loss: 6.7739 (6.7910)\n",
      "Epoch: [1][4/97] Time: 2.079 (1.852) Data: 1.017 (0.835) Loss: 6.8825 (6.8093)\n",
      "Epoch: [1][5/97] Time: 2.048 (1.885) Data: 1.113 (0.881) Loss: 6.8543 (6.8168)\n",
      "Epoch: [1][6/97] Time: 1.900 (1.887) Data: 0.969 (0.894) Loss: 6.8235 (6.8178)\n",
      "Epoch: [1][7/97] Time: 1.659 (1.858) Data: 0.720 (0.872) Loss: 6.8452 (6.8212)\n",
      "Epoch: [1][8/97] Time: 1.759 (1.847) Data: 0.720 (0.855) Loss: 6.8624 (6.8258)\n",
      "Epoch: [1][9/97] Time: 1.632 (1.826) Data: 0.703 (0.840) Loss: 6.8026 (6.8235)\n",
      "Epoch: [1][10/97] Time: 1.800 (1.823) Data: 0.730 (0.830) Loss: 6.7791 (6.8194)\n",
      "Epoch: [1][11/97] Time: 1.680 (1.812) Data: 0.740 (0.822) Loss: 6.8109 (6.8187)\n",
      "Epoch: [1][12/97] Time: 2.404 (1.857) Data: 1.348 (0.863) Loss: 6.7184 (6.8110)\n",
      "Epoch: [1][13/97] Time: 2.526 (1.905) Data: 1.504 (0.909) Loss: 6.7886 (6.8094)\n",
      "Epoch: [1][14/97] Time: 3.661 (2.022) Data: 2.548 (1.018) Loss: 6.7387 (6.8047)\n",
      "Epoch: [1][15/97] Time: 4.015 (2.147) Data: 2.881 (1.134) Loss: 6.7970 (6.8042)\n",
      "Epoch: [1][16/97] Time: 3.037 (2.199) Data: 1.854 (1.177) Loss: 6.6881 (6.7974)\n",
      "Epoch: [1][17/97] Time: 4.382 (2.320) Data: 3.231 (1.291) Loss: 6.6947 (6.7917)\n",
      "Epoch: [1][18/97] Time: 3.601 (2.388) Data: 2.408 (1.350) Loss: 6.5957 (6.7814)\n",
      "Epoch: [1][19/97] Time: 3.058 (2.421) Data: 1.849 (1.375) Loss: 6.7689 (6.7807)\n",
      "Epoch: [1][20/97] Time: 2.768 (2.438) Data: 1.685 (1.389) Loss: 6.6941 (6.7766)\n",
      "Epoch: [1][21/97] Time: 2.510 (2.441) Data: 1.448 (1.392) Loss: 6.6611 (6.7714)\n",
      "Epoch: [1][22/97] Time: 3.768 (2.499) Data: 2.692 (1.448) Loss: 6.6277 (6.7651)\n",
      "Epoch: [1][23/97] Time: 3.582 (2.544) Data: 2.428 (1.489) Loss: 6.7490 (6.7644)\n",
      "Epoch: [1][24/97] Time: 3.618 (2.587) Data: 2.447 (1.528) Loss: 6.6709 (6.7607)\n",
      "Epoch: [1][25/97] Time: 4.036 (2.643) Data: 2.903 (1.581) Loss: 6.6653 (6.7570)\n",
      "Epoch: [1][26/97] Time: 4.441 (2.709) Data: 3.369 (1.647) Loss: 6.5304 (6.7486)\n",
      "Epoch: [1][27/97] Time: 5.002 (2.791) Data: 3.883 (1.727) Loss: 6.5910 (6.7430)\n",
      "Epoch: [1][28/97] Time: 5.440 (2.882) Data: 4.200 (1.812) Loss: 6.6327 (6.7392)\n",
      "Epoch: [1][29/97] Time: 6.836 (3.014) Data: 5.756 (1.943) Loss: 6.6055 (6.7347)\n",
      "Epoch: [1][30/97] Time: 5.207 (3.085) Data: 3.966 (2.009) Loss: 6.6394 (6.7317)\n",
      "Epoch: [1][31/97] Time: 4.402 (3.126) Data: 3.308 (2.049) Loss: 6.6550 (6.7293)\n",
      "Epoch: [1][32/97] Time: 3.397 (3.134) Data: 2.233 (2.055) Loss: 6.5550 (6.7240)\n",
      "Epoch: [1][33/97] Time: 4.630 (3.178) Data: 3.506 (2.097) Loss: 6.6114 (6.7207)\n",
      "Epoch: [1][34/97] Time: 4.829 (3.225) Data: 3.714 (2.144) Loss: 6.6016 (6.7173)\n",
      "Epoch: [1][35/97] Time: 3.429 (3.231) Data: 2.361 (2.150) Loss: nan (nan)\n",
      "Epoch: [1][36/97] Time: 3.001 (3.225) Data: 1.882 (2.142) Loss: 6.6818 (nan)\n",
      "Epoch: [1][37/97] Time: 2.067 (3.194) Data: 1.129 (2.116) Loss: 6.6658 (nan)\n",
      "Epoch: [1][38/97] Time: 2.246 (3.170) Data: 1.305 (2.095) Loss: 6.6087 (nan)\n",
      "Epoch: [1][39/97] Time: 1.889 (3.138) Data: 0.947 (2.066) Loss: 6.6560 (nan)\n",
      "Epoch: [1][40/97] Time: 1.813 (3.106) Data: 0.891 (2.038) Loss: 6.6182 (nan)\n",
      "Epoch: [1][41/97] Time: 1.639 (3.071) Data: 0.708 (2.006) Loss: 6.5941 (nan)\n",
      "Epoch: [1][42/97] Time: 1.799 (3.041) Data: 0.772 (1.977) Loss: 6.5599 (nan)\n",
      "Epoch: [1][43/97] Time: 1.905 (3.015) Data: 0.833 (1.951) Loss: 6.5750 (nan)\n",
      "Epoch: [1][44/97] Time: 1.727 (2.987) Data: 0.796 (1.926) Loss: 6.5232 (nan)\n",
      "Epoch: [1][45/97] Time: 2.018 (2.966) Data: 0.973 (1.905) Loss: 6.5852 (nan)\n",
      "Epoch: [1][46/97] Time: 2.028 (2.946) Data: 1.094 (1.888) Loss: 6.6901 (nan)\n",
      "Epoch: [1][47/97] Time: 2.147 (2.929) Data: 1.042 (1.870) Loss: 6.4856 (nan)\n",
      "Epoch: [1][48/97] Time: 1.890 (2.908) Data: 0.849 (1.849) Loss: 6.5914 (nan)\n",
      "Epoch: [1][49/97] Time: 1.921 (2.888) Data: 0.774 (1.828) Loss: 6.6385 (nan)\n",
      "Epoch: [1][50/97] Time: 1.869 (2.868) Data: 0.938 (1.810) Loss: 6.5131 (nan)\n",
      "Epoch: [1][51/97] Time: 1.832 (2.848) Data: 0.790 (1.791) Loss: 6.5233 (nan)\n",
      "Epoch: [1][52/97] Time: 2.367 (2.839) Data: 1.318 (1.782) Loss: 6.3428 (nan)\n",
      "Epoch: [1][53/97] Time: 2.282 (2.829) Data: 1.354 (1.774) Loss: 6.4971 (nan)\n",
      "Epoch: [1][54/97] Time: 2.224 (2.818) Data: 1.162 (1.763) Loss: 6.5316 (nan)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m301\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 30\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))         \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# measure elapsed time\u001b[39;00m\n\u001b[0;32m     33\u001b[0m batch_time\u001b[38;5;241m.\u001b[39mupdate(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m end)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+301):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f18960-5cee-4c75-8e2d-fbe029643134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c411d9-e197-4ef9-a826-ac91d780b31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f0692-5012-4708-8799-7181d5581011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcd9a0-e4e2-4773-aae9-d30c4afc60d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ba9bf-e864-4a63-b555-d4ceeff754d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e59dfb-89c5-43d8-8331-4a2208e4a666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbdd28-8175-4176-8593-1b2e18a1067e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7988f2-5e02-4ac1-a508-76c54e49dbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a5b33-316f-4095-80db-67f62da1d74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894af6d-71b8-4c28-bfac-9de5fde15a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb517aa-29cc-499e-920c-ac05b67f510c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
